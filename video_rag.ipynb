{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d9e12dd-8913-431a-bacb-1c190dffd702",
   "metadata": {},
   "source": [
    "# Video Search App"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7c83d5-0b90-40eb-9699-eef1192b80e7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5aef0f-ad9c-4b85-ace2-f438fe6396a2",
   "metadata": {},
   "source": [
    "### Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "248dd395-eb5f-44fb-87eb-157342c80757",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installation done\n"
     ]
    }
   ],
   "source": [
    "# !pip install -q --upgrade google-cloud-aiplatform \n",
    "!pip install -q --upgrade google-cloud-dlp python-docx --upgrade google-auth\n",
    "!pip install -q --upgrade google-cloud-videointelligence\n",
    "!pip install -q bigframes==0.26\n",
    "!pip install -q --upgrade moviepy\n",
    "!pip install -q --upgrade ffmpeg\n",
    "!pip install -q unidecode\n",
    "!pip install -q --upgrade youtube-dl\n",
    "!pip install -q --upgrade pytubefix\n",
    "!pip install -q langchain_google_vertexai\n",
    "!pip install -U -q langchain langchainhub langchain-openai\n",
    "\n",
    "import IPython\n",
    "import time\n",
    "\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)\n",
    "\n",
    "time.sleep(10)\n",
    "\n",
    "print(\"Installation done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a932cfa5-9443-4fd1-956c-d462530d38f7",
   "metadata": {},
   "source": [
    "### Setup Environment Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ec4ac1-c0c9-4739-8e9a-16758cfe2ea9",
   "metadata": {},
   "source": [
    "#### Once Kernel restarts, run this cell and all below\n",
    "##### Run > Run selected cell and all below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e7c27afe-3cbd-47ad-ae5f-10613999f0a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_google_vertexai import VertexAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "823d2dd9-21f0-434a-a84c-389e6c46c251",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\n",
      "Creating gs://ai-sb-test-fluxtest-us-central1/...\n",
      "\u001b[1;31mERROR:\u001b[0m (gcloud.storage.buckets.create) HTTPError 409: Your previous request to create the named bucket succeeded and you already own it.\n"
     ]
    }
   ],
   "source": [
    "import socket\n",
    "import re\n",
    "\n",
    "PROJECT_ID = !(gcloud config get-value core/project)\n",
    "PROJECT_ID = PROJECT_ID[0]\n",
    "\n",
    "SVC_ACC = !(gcloud config get-value core/account)\n",
    "SVC_ACC = SVC_ACC[0]\n",
    "\n",
    "PROJECT_NUMBER=str(re.search(r'\\d+', SVC_ACC).group())\n",
    "\n",
    "LOCATION=\"us-central1\"\n",
    "\n",
    "UNIQUE_PREFIX = socket.gethostname()\n",
    "UNIQUE_PREFIX = re.sub('[^A-Za-z0-9]+', '', UNIQUE_PREFIX)\n",
    "\n",
    "UID = \"JTC\"\n",
    "\n",
    "BUCKET_NAME = f\"{PROJECT_ID}-{UNIQUE_PREFIX}-{LOCATION}\"\n",
    "\n",
    "BUCKET_URI = f\"gs://{BUCKET_NAME}\"\n",
    "\n",
    "! gcloud config set project $PROJECT_ID\n",
    "! gcloud storage buckets create {BUCKET_URI} --project={PROJECT_ID} --location={LOCATION}\n",
    "\n",
    "!rm -r -f content\n",
    "!mkdir content\n",
    "!mkdir content/clips/\n",
    "!mkdir content/frames/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2829d182-c08a-4493-bd3d-8cbae9b28ded",
   "metadata": {},
   "source": [
    "### Initialize Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d5f14b9a-cc6b-43dd-a3e5-8f5e505154fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import vertexai\n",
    "from vertexai.language_models import TextEmbeddingModel\n",
    "from vertexai.vision_models import Image as vision_model_Image\n",
    "from vertexai.vision_models import MultiModalEmbeddingModel\n",
    "import glob\n",
    "import os\n",
    "import time\n",
    "from typing import Any, Dict, Iterable, List, Optional, Tuple, Union\n",
    "from IPython.display import display\n",
    "import PIL\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from vertexai.generative_models import (\n",
    "    GenerationConfig,\n",
    "    HarmBlockThreshold,\n",
    "    HarmCategory,\n",
    "    Image,\n",
    ")\n",
    "from vertexai.language_models import TextEmbeddingModel\n",
    "from vertexai.vision_models import Image as vision_model_Image\n",
    "from vertexai.vision_models import MultiModalEmbeddingModel\n",
    "from moviepy.editor import VideoFileClip\n",
    "from google.api_core.client_options import ClientOptions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa7663a-2782-4f6f-8497-4fa99f86faaa",
   "metadata": {},
   "source": [
    "### Download and upload videos to a bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d1503e-080b-4748-9dcc-cbe127a778fe",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8ab91cec-29ca-4c02-aff4-048f47f1feaa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pytube\n",
    "from google.cloud import storage\n",
    "import unidecode\n",
    "from pytubefix import YouTube\n",
    "\n",
    "# -1.1) Fetching from youtube\n",
    "def download_video(video_url, download_folder):\n",
    "    # Create a YouTube object\n",
    "    yt = YouTube(video_url)\n",
    "    \n",
    "    # Filter to get the highest resolution stream that includes both video and audio\n",
    "    stream = yt.streams.filter(progressive=True, file_extension='mp4').order_by('resolution').desc().first()\n",
    "    \n",
    "    # Download the video\n",
    "    if stream:\n",
    "        print(f\"Going to download {video_url}\")\n",
    "        \n",
    "        # Create download path with filename\n",
    "        download_path = os.path.join(download_folder)\n",
    "\n",
    "        # Download the video to the specified path\n",
    "        stream.download(output_path=download_path)\n",
    "\n",
    "        print(f\"Downloaded into {download_path}\")\n",
    "        return stream.title\n",
    "    else:\n",
    "        print(\"No suitable stream found\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def upload_file_to_gcs(bucket_name, source_file_path, destination_blob_name):\n",
    "    client = storage.Client()\n",
    "    bucket = client.bucket(bucket_name)\n",
    "    blob = bucket.blob(destination_blob_name)\n",
    "    blob.upload_from_filename(source_file_path)\n",
    "    return blob\n",
    "\n",
    "def upload_file_to_bucket(bucket_name, source_file_path_name): \n",
    "    source_file_path = f\"./{source_file_path_name}\"\n",
    "    destination_blob_name = source_file_path_name.replace(' ', '_')\n",
    "    destination_blob_name = unidecode.unidecode(destination_blob_name)\n",
    "    uploaded_blob         = upload_file_to_gcs(bucket_name, source_file_path, destination_blob_name)\n",
    "    print(f\"File [{source_file_path}] \\nUploaded to [{uploaded_blob.name}] \\nIn bucket [{bucket_name}]\")\n",
    "    return destination_blob_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8307e3-dfca-4830-95fd-9e6ae641f35c",
   "metadata": {},
   "source": [
    "### Download Videos from youtube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b482cf33-c527-49ae-865b-493f31158693",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Going to download https://www.youtube.com/watch?v=WKsgKA-YHmc\n",
      "Downloaded into ./content/videos\n",
      "Going to download https://www.youtube.com/watch?v=i4osPznQ5d0\n",
      "Downloaded into ./content/videos\n",
      "Going to download https://www.youtube.com/watch?v=XzipIUW8vF4\n",
      "Downloaded into ./content/videos\n",
      "Going to download https://www.youtube.com/watch?v=mfoj_hulL8Q\n",
      "Downloaded into ./content/videos\n",
      "Going to download https://www.youtube.com/watch?v=75E_xOkWeXY\n",
      "Downloaded into ./content/videos\n",
      "Going to download https://www.youtube.com/watch?v=iLQx08RkHvc\n",
      "Downloaded into ./content/videos\n",
      "Going to download https://www.youtube.com/watch?v=KQXrabmy6Ws\n",
      "Downloaded into ./content/videos\n"
     ]
    }
   ],
   "source": [
    "# Define the video URL\n",
    "video_url_list = [\n",
    "    \"https://www.youtube.com/watch?v=WKsgKA-YHmc\",\n",
    "    \"https://www.youtube.com/watch?v=i4osPznQ5d0\",\n",
    "    \"https://www.youtube.com/watch?v=XzipIUW8vF4\",\n",
    "    \"https://www.youtube.com/watch?v=mfoj_hulL8Q\",\n",
    "    \"https://www.youtube.com/watch?v=75E_xOkWeXY\",\n",
    "    \"https://www.youtube.com/watch?v=iLQx08RkHvc\",\n",
    "    \"https://www.youtube.com/watch?v=KQXrabmy6Ws\",\n",
    "    \n",
    "]\n",
    "\n",
    "downloaded_videos = []\n",
    "\n",
    "for video in video_url_list:\n",
    "    video_name = download_video(video,\"./content/videos\")\n",
    "    downloaded_videos.append(re.sub(r\"[^a-zA-Z0-9\\.\\s]\", \"\", video_name))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ff44cb-3c98-40c4-b195-8809ce1ed246",
   "metadata": {},
   "source": [
    "### Create csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "15767c04-0e63-48dd-96b0-97064c337e5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('shots.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    field = [\"id\", \"video_id\", \"video_title\", \"start_time\", \"end_time\", \"clip_name\", \"frame_name\", \"associated_text\", \"associated_speech\", \"associated_object\", \"description\"]\n",
    "    writer.writerow(field)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b22119-b765-4145-8c9c-57421bf65836",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Process videos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5772824-4fdc-4745-906c-60a2ea412486",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Generate video descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "679c83c1-f1b9-4b71-83a1-e8486c3c1672",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import base64\n",
    "import time\n",
    "import vertexai\n",
    "from vertexai.preview.generative_models import GenerativeModel, Part\n",
    "import vertexai.preview.generative_models as generative_models\n",
    "from vertexai.generative_models import Tool\n",
    "from vertexai.generative_models import grounding\n",
    "\n",
    "#Generate video description using AI Model\n",
    "#Model used is customisable (default = gemini-1.0-pro)\n",
    "\n",
    "desc_context = \"\"\"You are provided with a short video. First, watch the whole video in full. Then, \n",
    "    describe the contents of the video in chronological order.\n",
    "    Go into as much detail as possible.\"\"\"\n",
    "\n",
    "text_context = \"\"\"You are provided with a short video. Register every text visible in chronological order.\n",
    "    Do not include audio. Only include what you can see visually.\"\"\"\n",
    "\n",
    "speech_context = \"\"\"You are provided with a short video. Watch the video in full, and listen to the audio.\n",
    "    Register everything you hear in chronological order. Convert everything into text, word for word.\"\"\"\n",
    "\n",
    "object_context = \"\"\"You are provided with a short video. If there are people or animals in the video, describe all the different people or animals that appear throughout the video. Associate them with\n",
    "    a name if mentioned.\n",
    "    Include their appearance, emotions, actions if possible. Do so in great detail. If there are no people or animals, simply state that there aren't any. \"\"\"\n",
    "\n",
    "def generate(prompt, video):\n",
    "    vertexai.init(project=PROJECT_ID, location=\"us-central1\")\n",
    "    model = GenerativeModel(\"gemini-1.5-flash-002\")\n",
    "    max_retry = 5\n",
    "    retry = 0\n",
    "    success = False\n",
    "    for i in range(5):\n",
    "        try:\n",
    "            responses = model.generate_content(\n",
    "            [prompt, video],\n",
    "            generation_config={\n",
    "                \"max_output_tokens\": 2048,\n",
    "                \"temperature\": 0,\n",
    "                \"top_p\": 0.4,\n",
    "                \"top_k\": 32\n",
    "            },\n",
    "            safety_settings={\n",
    "                  generative_models.HarmCategory.HARM_CATEGORY_HATE_SPEECH: generative_models.HarmBlockThreshold.BLOCK_NONE,\n",
    "                  generative_models.HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: generative_models.HarmBlockThreshold.BLOCK_NONE,\n",
    "                  generative_models.HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: generative_models.HarmBlockThreshold.BLOCK_NONE,\n",
    "                  generative_models.HarmCategory.HARM_CATEGORY_HARASSMENT: generative_models.HarmBlockThreshold.BLOCK_NONE,\n",
    "            },\n",
    "            stream=False,\n",
    "            )\n",
    "            return responses\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            time.sleep(5)\n",
    "            print(\"retrying\")\n",
    "    raise Exception(\"Failed to generate response after 5 retries\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9124340e-795e-41fd-a85e-326adef6811a",
   "metadata": {},
   "source": [
    "## Split Videos into 1 minute clips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "034d4183-2240-4cd1-ad36-8987c9f7da02",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "content/clips/Open Digital Platform A smart district operating system_clip_0.mp4 has been processed.\n",
      "\n",
      "content/clips/Open Digital Platform A smart district operating system_clip_1.mp4 has been processed.\n",
      "\n",
      "content/clips/Open Digital Platform A smart district operating system_clip_2.mp4 has been processed.\n",
      "\n",
      "content/clips/Open Digital Platform A smart district operating system_clip_3.mp4 has been processed.\n",
      "\n",
      "content/clips/FIABCI delegates visit Punggol Digital District_clip_0.mp4 has been processed.\n",
      "\n",
      "content/clips/FIABCI delegates visit Punggol Digital District_clip_1.mp4 has been processed.\n",
      "\n",
      "content/clips/JID Day Insights Pushing the Boundaries of Sustainable Design_clip_0.mp4 has been processed.\n",
      "\n",
      "content/clips/JID Day Insights Pushing the Boundaries of Sustainable Design_clip_1.mp4 has been processed.\n",
      "\n",
      "content/clips/JID Day Insights Pushing the Boundaries of Sustainable Design_clip_2.mp4 has been processed.\n",
      "\n",
      "content/clips/JID Day Insights Pushing the Boundaries of Sustainable Design_clip_3.mp4 has been processed.\n",
      "\n",
      "content/clips/10 Sustainable Design and Infrastructure Features at Punggol Digital District_clip_0.mp4 has been processed.\n",
      "\n",
      "content/clips/10 Sustainable Design and Infrastructure Features at Punggol Digital District_clip_1.mp4 has been processed.\n",
      "\n",
      "content/clips/10 Sustainable Design and Infrastructure Features at Punggol Digital District_clip_2.mp4 has been processed.\n",
      "\n",
      "content/clips/8 hours of work done in just 2.5 hours Thats the power of automation_clip_0.mp4 has been processed.\n",
      "\n",
      "content/clips/8 hours of work done in just 2.5 hours Thats the power of automation_clip_1.mp4 has been processed.\n",
      "\n",
      "content/clips/Whats Happening at SWITCH  onenorth_clip_0.mp4 has been processed.\n",
      "\n",
      "content/clips/Whats Happening at SWITCH  onenorth_clip_1.mp4 has been processed.\n",
      "\n",
      "content/clips/Punggol Digital District The future is yours to create_clip_0.mp4 has been processed.\n",
      "\n",
      "content/clips/Punggol Digital District The future is yours to create_clip_1.mp4 has been processed.\n",
      "\n",
      "content/clips/Punggol Digital District The future is yours to create_clip_2.mp4 has been processed.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>video_id</th>\n",
       "      <th>video_title</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>clip_name</th>\n",
       "      <th>frame_name</th>\n",
       "      <th>associated_text</th>\n",
       "      <th>associated_speech</th>\n",
       "      <th>associated_object</th>\n",
       "      <th>description</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>Open Digital Platform A smart district operati...</td>\n",
       "      <td>0</td>\n",
       "      <td>60.00</td>\n",
       "      <td>content/clips/Open Digital Platform A smart di...</td>\n",
       "      <td>content/frames/frame_0.png</td>\n",
       "      <td>Security Counter\\nOur digital landscape is pow...</td>\n",
       "      <td>Our digital landscape is powered by data.\\nAnd...</td>\n",
       "      <td>Here is a description of the people in the vid...</td>\n",
       "      <td>Here is a description of the video in chronolo...</td>\n",
       "      <td>[0.023411588743329048, 0.020503206178545952, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Open Digital Platform A smart district operati...</td>\n",
       "      <td>60</td>\n",
       "      <td>120.00</td>\n",
       "      <td>content/clips/Open Digital Platform A smart di...</td>\n",
       "      <td>content/frames/frame_1.png</td>\n",
       "      <td>Here is a list of the text visible in the vide...</td>\n",
       "      <td>Developed by JTC and GovTech, in collaboration...</td>\n",
       "      <td>Here is a description of the people in the vid...</td>\n",
       "      <td>Here is a description of the video in chronolo...</td>\n",
       "      <td>[0.020479103550314903, 0.0032895293552428484, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Open Digital Platform A smart district operati...</td>\n",
       "      <td>120</td>\n",
       "      <td>180.00</td>\n",
       "      <td>content/clips/Open Digital Platform A smart di...</td>\n",
       "      <td>content/frames/frame_2.png</td>\n",
       "      <td>Here is a list of the text visible in the vide...</td>\n",
       "      <td>the platform can then tap on these data sets f...</td>\n",
       "      <td>Here is a description of the people in the pro...</td>\n",
       "      <td>Here is a description of the video in chronolo...</td>\n",
       "      <td>[-0.01953345350921154, 0.0030750450678169727, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Open Digital Platform A smart district operati...</td>\n",
       "      <td>180</td>\n",
       "      <td>186.36</td>\n",
       "      <td>content/clips/Open Digital Platform A smart di...</td>\n",
       "      <td>content/frames/frame_3.png</td>\n",
       "      <td>Here's a list of the text visible in the video...</td>\n",
       "      <td>Here's a transcription of the audio from the p...</td>\n",
       "      <td>There are no people or animals in this video.</td>\n",
       "      <td>The video begins with a QR code and a website ...</td>\n",
       "      <td>[-0.00630419235676527, -0.006567784119397402, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>FIABCI delegates visit Punggol Digital District</td>\n",
       "      <td>0</td>\n",
       "      <td>60.00</td>\n",
       "      <td>content/clips/FIABCI delegates visit Punggol D...</td>\n",
       "      <td>content/frames/frame_0.png</td>\n",
       "      <td>Here is a listing of all the text visible in t...</td>\n",
       "      <td>Here's a transcription of the audio from the p...</td>\n",
       "      <td>Here is a description of the people in the pro...</td>\n",
       "      <td>Here is a description of the video in chronolo...</td>\n",
       "      <td>[0.013792615383863449, 0.014185289852321148, -...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  video_id                                        video_title  \\\n",
       "0  -1         1  Open Digital Platform A smart district operati...   \n",
       "1   0         1  Open Digital Platform A smart district operati...   \n",
       "2   1         1  Open Digital Platform A smart district operati...   \n",
       "3   2         1  Open Digital Platform A smart district operati...   \n",
       "4   3         2    FIABCI delegates visit Punggol Digital District   \n",
       "\n",
       "   start_time  end_time                                          clip_name  \\\n",
       "0           0     60.00  content/clips/Open Digital Platform A smart di...   \n",
       "1          60    120.00  content/clips/Open Digital Platform A smart di...   \n",
       "2         120    180.00  content/clips/Open Digital Platform A smart di...   \n",
       "3         180    186.36  content/clips/Open Digital Platform A smart di...   \n",
       "4           0     60.00  content/clips/FIABCI delegates visit Punggol D...   \n",
       "\n",
       "                   frame_name  \\\n",
       "0  content/frames/frame_0.png   \n",
       "1  content/frames/frame_1.png   \n",
       "2  content/frames/frame_2.png   \n",
       "3  content/frames/frame_3.png   \n",
       "4  content/frames/frame_0.png   \n",
       "\n",
       "                                     associated_text  \\\n",
       "0  Security Counter\\nOur digital landscape is pow...   \n",
       "1  Here is a list of the text visible in the vide...   \n",
       "2  Here is a list of the text visible in the vide...   \n",
       "3  Here's a list of the text visible in the video...   \n",
       "4  Here is a listing of all the text visible in t...   \n",
       "\n",
       "                                   associated_speech  \\\n",
       "0  Our digital landscape is powered by data.\\nAnd...   \n",
       "1  Developed by JTC and GovTech, in collaboration...   \n",
       "2  the platform can then tap on these data sets f...   \n",
       "3  Here's a transcription of the audio from the p...   \n",
       "4  Here's a transcription of the audio from the p...   \n",
       "\n",
       "                                   associated_object  \\\n",
       "0  Here is a description of the people in the vid...   \n",
       "1  Here is a description of the people in the vid...   \n",
       "2  Here is a description of the people in the pro...   \n",
       "3      There are no people or animals in this video.   \n",
       "4  Here is a description of the people in the pro...   \n",
       "\n",
       "                                         description  \\\n",
       "0  Here is a description of the video in chronolo...   \n",
       "1  Here is a description of the video in chronolo...   \n",
       "2  Here is a description of the video in chronolo...   \n",
       "3  The video begins with a QR code and a website ...   \n",
       "4  Here is a description of the video in chronolo...   \n",
       "\n",
       "                                           embedding  \n",
       "0  [0.023411588743329048, 0.020503206178545952, -...  \n",
       "1  [0.020479103550314903, 0.0032895293552428484, ...  \n",
       "2  [-0.01953345350921154, 0.0030750450678169727, ...  \n",
       "3  [-0.00630419235676527, -0.006567784119397402, ...  \n",
       "4  [0.013792615383863449, 0.014185289852321148, -...  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import moviepy.editor as mpe\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "from vertexai.language_models import TextEmbeddingModel\n",
    "text_embedding_model = TextEmbeddingModel.from_pretrained(\"textembedding-gecko@003\")\n",
    "\n",
    "shots_list = []\n",
    "\n",
    "shots_df = pd.read_csv('shots.csv')\n",
    "\n",
    "id_list = []\n",
    "unnamed_id_list = []\n",
    "video_title_list = []\n",
    "start_time_list = []\n",
    "end_time_list = []\n",
    "clip_name_list = []\n",
    "frame_name_list = []\n",
    "associated_desc=[]\n",
    "associated_speech=[]\n",
    "associated_text=[]\n",
    "associated_object=[]\n",
    "embeddingsList = []\n",
    "\n",
    "videoPath = \"./content/videos/\"\n",
    "\n",
    "file_number = 0\n",
    "clip_id = -1\n",
    "\n",
    "for videoFile in os.listdir(videoPath):\n",
    "    \n",
    "    if os.path.isfile(os.path.join(videoPath, videoFile)):  # Check if it's a file\n",
    "        video_name = (re.sub(r\"[^a-zA-Z0-9\\.\\s]\", \"\", videoFile))[:-4]\n",
    "        try:\n",
    "            video = mpe.VideoFileClip(videoPath + videoFile)\n",
    "            \n",
    "            # e.g. Cut into 60s clips (Change clip_duration to set the desired duration of subclips)\n",
    "            clip_duration = 60\n",
    "            clip_no = math.ceil(video.duration/clip_duration)\n",
    "            clip_no = int(clip_no)\n",
    "\n",
    "            file_number += 1    \n",
    "\n",
    "            for i in range(clip_no):\n",
    "                start_time = i * clip_duration\n",
    "                end_time = min(start_time + clip_duration, video.duration)\n",
    "\n",
    "                text = \"\"\n",
    "                clip_name = f\"content/clips/{video_name}_clip_\"+str(i)+\".mp4\"\n",
    "                video.subclip(start_time, end_time).write_videofile(clip_name, logger=None)\n",
    "                time = (start_time  + end_time)/2\n",
    "\n",
    "                # saving a frame at 2 second\n",
    "                frame_name = \"content/frames/frame_\"+str(i)+\".png\"\n",
    "                video.save_frame(frame_name, t = float(time))\n",
    "\n",
    "                id_list.append(clip_id)\n",
    "                unnamed_id_list.append(file_number)\n",
    "                video_title_list.append(video_name)\n",
    "                start_time_list.append(start_time)\n",
    "                end_time_list.append(end_time)\n",
    "                clip_name_list.append(clip_name)\n",
    "                frame_name_list.append(frame_name)\n",
    "\n",
    "                # Process the clips\n",
    "\n",
    "                with open(clip_name, \"rb\") as f:\n",
    "                    text = base64.b64encode(f.read())\n",
    "                    clip = Part.from_data(data=base64.b64decode(text), mime_type=\"video/mp4\")\n",
    "\n",
    "                    desc = generate(desc_context, clip).text\n",
    "                    associated_desc.append(desc)\n",
    "                    speechDesc = generate(speech_context, clip).text\n",
    "                    associated_speech.append(speechDesc)\n",
    "                    textDesc = generate(text_context, clip).text\n",
    "                    associated_text.append(textDesc)\n",
    "                    objDesc = generate(object_context, clip).text\n",
    "                    associated_object.append(objDesc)\n",
    "\n",
    "                    string = desc + \"\\n\" + speechDesc + \"\\n\" + textDesc + \"\\n\" +  objDesc\n",
    "                    embeddings = text_embedding_model.get_embeddings([string])\n",
    "                    text_embedding = [embedding.values for embedding in embeddings][0]\n",
    "                    embeddingsList.append(text_embedding)\n",
    "\n",
    "                clip_id += 1\n",
    "                \n",
    "                print(f\"\\n{clip_name} has been processed.\")\n",
    "        except OSError:\n",
    "            print(f\"Error processing {videoFile}. Skipping.\")\n",
    "            continue\n",
    "\n",
    "shots_df['id'] = id_list        \n",
    "shots_df['video_id'] = unnamed_id_list\n",
    "shots_df['video_title'] = video_title_list\n",
    "shots_df['start_time'] = start_time_list\n",
    "shots_df['end_time'] = end_time_list\n",
    "shots_df['clip_name'] = clip_name_list\n",
    "shots_df['frame_name'] = frame_name_list\n",
    "\n",
    "shots_df['description'] = associated_desc\n",
    "shots_df['associated_speech'] = associated_speech\n",
    "shots_df['associated_text'] = associated_text\n",
    "shots_df['associated_object'] = associated_object\n",
    "shots_df[\"embedding\"] = embeddingsList\n",
    "shots_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37e7bd0-e978-40b0-9ff6-856bca402dc1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b70c07e-fcb1-4560-90f9-61082536953e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Convert Dataframe into CSV and store in bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "39b69218-7bf9-4586-9823-c45227159e5c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://content/shots.csv [Content-Type=text/csv]...\n",
      "- [1 files][433.6 KiB/433.6 KiB]                                                \n",
      "Operation completed over 1 objects/433.6 KiB.                                    \n"
     ]
    }
   ],
   "source": [
    "shots_df.to_csv('content/shots.csv')\n",
    "# Copy the file to our new bucket.\n",
    "!gsutil cp content/shots.csv {BUCKET_URI}/shots.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3b1956-0c36-4a87-8a81-715fad307411",
   "metadata": {},
   "source": [
    "### Convert the Dataframe into a JSON file, which will be uploaded into Vector Search Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "6152d8e8-6b82-41ba-9a0e-de72d1f4fcd8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "BUCKET_URI_ME=f\"{BUCKET_URI}/embeddings/\"\n",
    "LOCATION = 'us-central1'\n",
    "\n",
    "from google.cloud import aiplatform\n",
    "\n",
    "aiplatform.init(project=PROJECT_ID, location=LOCATION)\n",
    "\n",
    "jsonl_string = shots_df[['id','video_id','video_title','start_time','end_time','clip_name', 'frame_name', \"associated_text\", \"associated_speech\", \"associated_object\", \"description\", \"embedding\"]].to_json(orient=\"records\", lines=True)\n",
    "with open(f\"./videodata.json\", \"w\") as f:\n",
    "    f.write(jsonl_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "683ba9bf-2079-41c0-a51b-2e11e9bca8ac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://videodata.json [Content-Type=application/json]...\n",
      "- [1 files][308.3 KiB/308.3 KiB]                                                \n",
      "Operation completed over 1 objects/308.3 KiB.                                    \n"
     ]
    }
   ],
   "source": [
    "! gsutil cp videodata.json {BUCKET_URI_ME}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf914184-1944-4996-9de9-f7f1150b129e",
   "metadata": {},
   "source": [
    "## Creating Vector Search Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a7fba175-9018-4dea-b4f1-19ea07180066",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating MatchingEngineIndex\n",
      "Create MatchingEngineIndex backing LRO: projects/849276838208/locations/us-central1/indexes/1509246834889981952/operations/2378069550085177344\n",
      "MatchingEngineIndex created. Resource name: projects/849276838208/locations/us-central1/indexes/1509246834889981952\n",
      "To use this MatchingEngineIndex in another session:\n",
      "index = aiplatform.MatchingEngineIndex('projects/849276838208/locations/us-central1/indexes/1509246834889981952')\n"
     ]
    }
   ],
   "source": [
    "# create Index\n",
    "my_index = aiplatform.MatchingEngineIndex.create_tree_ah_index(\n",
    "    display_name=f\"vs_index_{UID}\",\n",
    "    contents_delta_uri=BUCKET_URI_ME,\n",
    "    dimensions=768,\n",
    "    approximate_neighbors_count=10,\n",
    "    project = PROJECT_ID\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab66e05f-22c0-4225-bb12-06286e016252",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Create Index Endpoint and deploy the Index\n",
    "To use the Index, you need to create an Index Endpoint. It works as a server instance accepting query requests for your Index.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "72c81bf3-11f8-4536-ad33-ad3ad6ebfdd3",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating MatchingEngineIndexEndpoint\n",
      "Create MatchingEngineIndexEndpoint backing LRO: projects/849276838208/locations/us-central1/indexEndpoints/9115967343007105024/operations/7956481376025313280\n",
      "MatchingEngineIndexEndpoint created. Resource name: projects/849276838208/locations/us-central1/indexEndpoints/9115967343007105024\n",
      "To use this MatchingEngineIndexEndpoint in another session:\n",
      "index_endpoint = aiplatform.MatchingEngineIndexEndpoint('projects/849276838208/locations/us-central1/indexEndpoints/9115967343007105024')\n"
     ]
    }
   ],
   "source": [
    "# create IndexEndpoint\n",
    "my_index_endpoint = aiplatform.MatchingEngineIndexEndpoint.create(\n",
    "    display_name=f\"vs_endpoint_{UID}\", public_endpoint_enabled=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "77a5f274-a090-4477-b296-5fa2f02f8b35",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deploying index MatchingEngineIndexEndpoint index_endpoint: projects/849276838208/locations/us-central1/indexEndpoints/9115967343007105024\n",
      "Deploy index MatchingEngineIndexEndpoint index_endpoint backing LRO: projects/849276838208/locations/us-central1/indexEndpoints/9115967343007105024/operations/1801608797781753856\n",
      "MatchingEngineIndexEndpoint index_endpoint Deployed index. Resource name: projects/849276838208/locations/us-central1/indexEndpoints/9115967343007105024\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<google.cloud.aiplatform.matching_engine.matching_engine_index_endpoint.MatchingEngineIndexEndpoint object at 0x7f553b6030a0> \n",
       "resource name: projects/849276838208/locations/us-central1/indexEndpoints/9115967343007105024"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEPLOYED_INDEX_ID = f\"vs_deployed_{UID}\"\n",
    "# deploy the Index to the Index Endpoint\n",
    "my_index_endpoint.deploy_index(index=my_index, deployed_index_id=DEPLOYED_INDEX_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc16288d-f9f0-4f29-898c-5100fb83284a",
   "metadata": {},
   "source": [
    "#### Go to your Vertex AI console and check that the index is CREATED successfully "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3ba04c-a5ec-432b-a098-1205d937647f",
   "metadata": {},
   "source": [
    "### Get an existing Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "86531ab4-261a-4f34-924c-cce05d4cb0b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "fb63a10d-c8ab-455e-a9af-65c609f280d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "REGION = LOCATION = \"us-central1\"\n",
    "\n",
    "aiplatform.init(project=PROJECT_ID, location=LOCATION)\n",
    "vertexai.init(project=PROJECT_ID, location=LOCATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "bbe54c90-9902-4e70-84a1-33f7ef9636c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Uncomment below to manually insert Index \n",
    "# my_index_id = \"8368299436119425024\"\n",
    "# my_index = aiplatform.MatchingEngineIndex(my_index_id)\n",
    "\n",
    "my_index_name = my_index._gca_resource.name\n",
    "my_index_display_name = my_index.display_name\n",
    "my_index_id = my_index.name.split('/')[-1]\n",
    "\n",
    "my_index_endpoint_name = my_index_endpoint._gca_resource.name\n",
    "my_index_endpoint_display_name = my_index_endpoint.display_name\n",
    "my_index_endpoint_id = my_index_endpoint.name.split('/')[-1]\n",
    "my_index_endpoint_public_domain = my_index_endpoint.public_endpoint_domain_name\n",
    "\n",
    "my_index = aiplatform.MatchingEngineIndex(my_index_name)\n",
    "\n",
    "my_index_endpoint = aiplatform.MatchingEngineIndexEndpoint(my_index_endpoint_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "2829325d-9680-445e-9ad1-4eefd4029f8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set variables for the current deployed index.\n",
    "API_ENDPOINT=my_index_endpoint_public_domain\n",
    "INDEX_ENDPOINT=my_index_endpoint_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "d4b9293b-ad30-414f-8e6b-b9009475f2a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_google_vertexai import VertexAIEmbeddings\n",
    "from google.cloud import aiplatform_v1\n",
    "\n",
    "embeddings = VertexAIEmbeddings(model=\"textembedding-gecko@003\")\n",
    "\n",
    "text_embedding_model = embeddings #TextEmbeddingModel.from_pretrained(\"textembedding-gecko@003\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df9812c-c1ee-423a-af56-7235da1e1e9a",
   "metadata": {},
   "source": [
    "### Querying using Vector Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "949c0248-1299-4e33-b0dc-f6f34155ec24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Set your query\n",
    "query = \"Did FIABCI delegates visit Punggol\"\n",
    "\n",
    "#Set the number of results you want\n",
    "neighbor_count = 3\n",
    "\n",
    "test_embeddings = embeddings.embed_query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "24599c7d-0abc-46cb-997a-93c6c7c54c78",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1369639239.us-central1-849276838208.vdb.vertexai.goog'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "API_ENDPOINT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "1e74441a-4107-49a3-987f-e8918df3d45b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>video_id</th>\n",
       "      <th>video_title</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>clip_name</th>\n",
       "      <th>frame_name</th>\n",
       "      <th>associated_text</th>\n",
       "      <th>associated_speech</th>\n",
       "      <th>associated_object</th>\n",
       "      <th>description</th>\n",
       "      <th>embedding</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>10 Sustainable Design and Infrastructure Featu...</td>\n",
       "      <td>120</td>\n",
       "      <td>157.18</td>\n",
       "      <td>content/clips/10 Sustainable Design and Infras...</td>\n",
       "      <td>content/frames/frame_2.png</td>\n",
       "      <td>Here is a listing of all the text visible in t...</td>\n",
       "      <td>Certainly! Here is a transcription of the audi...</td>\n",
       "      <td>Here is a description of the people and animal...</td>\n",
       "      <td>Here is a description of the video in chronolo...</td>\n",
       "      <td>[-0.002668655477464199, -0.0018522889586165547...</td>\n",
       "      <td>0.632236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>FIABCI delegates visit Punggol Digital District</td>\n",
       "      <td>0</td>\n",
       "      <td>60.00</td>\n",
       "      <td>content/clips/FIABCI delegates visit Punggol D...</td>\n",
       "      <td>content/frames/frame_0.png</td>\n",
       "      <td>Here is a listing of all the text visible in t...</td>\n",
       "      <td>Here's a transcription of the audio from the p...</td>\n",
       "      <td>Here is a description of the people in the pro...</td>\n",
       "      <td>Here is a description of the video in chronolo...</td>\n",
       "      <td>[0.013792615383863449, 0.014185289852321148, -...</td>\n",
       "      <td>0.665848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>FIABCI delegates visit Punggol Digital District</td>\n",
       "      <td>60</td>\n",
       "      <td>91.32</td>\n",
       "      <td>content/clips/FIABCI delegates visit Punggol D...</td>\n",
       "      <td>content/frames/frame_1.png</td>\n",
       "      <td>Here is a list of the text visible in the vide...</td>\n",
       "      <td>of how to use the data to organise the living,...</td>\n",
       "      <td>Certainly, here is a description of the people...</td>\n",
       "      <td>Here is a description of the video in chronolo...</td>\n",
       "      <td>[0.004918518476188183, 0.011962203308939934, -...</td>\n",
       "      <td>0.669026</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  video_id                                        video_title  \\\n",
       "12  11         4  10 Sustainable Design and Infrastructure Featu...   \n",
       "4    3         2    FIABCI delegates visit Punggol Digital District   \n",
       "5    4         2    FIABCI delegates visit Punggol Digital District   \n",
       "\n",
       "    start_time  end_time                                          clip_name  \\\n",
       "12         120    157.18  content/clips/10 Sustainable Design and Infras...   \n",
       "4            0     60.00  content/clips/FIABCI delegates visit Punggol D...   \n",
       "5           60     91.32  content/clips/FIABCI delegates visit Punggol D...   \n",
       "\n",
       "                    frame_name  \\\n",
       "12  content/frames/frame_2.png   \n",
       "4   content/frames/frame_0.png   \n",
       "5   content/frames/frame_1.png   \n",
       "\n",
       "                                      associated_text  \\\n",
       "12  Here is a listing of all the text visible in t...   \n",
       "4   Here is a listing of all the text visible in t...   \n",
       "5   Here is a list of the text visible in the vide...   \n",
       "\n",
       "                                    associated_speech  \\\n",
       "12  Certainly! Here is a transcription of the audi...   \n",
       "4   Here's a transcription of the audio from the p...   \n",
       "5   of how to use the data to organise the living,...   \n",
       "\n",
       "                                    associated_object  \\\n",
       "12  Here is a description of the people and animal...   \n",
       "4   Here is a description of the people in the pro...   \n",
       "5   Certainly, here is a description of the people...   \n",
       "\n",
       "                                          description  \\\n",
       "12  Here is a description of the video in chronolo...   \n",
       "4   Here is a description of the video in chronolo...   \n",
       "5   Here is a description of the video in chronolo...   \n",
       "\n",
       "                                            embedding  distance  \n",
       "12  [-0.002668655477464199, -0.0018522889586165547...  0.632236  \n",
       "4   [0.013792615383863449, 0.014185289852321148, -...  0.665848  \n",
       "5   [0.004918518476188183, 0.011962203308939934, -...  0.669026  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Configure Vector Search client\n",
    "client_options = {\n",
    "  \"api_endpoint\": API_ENDPOINT\n",
    "}\n",
    "vector_search_client = aiplatform_v1.MatchServiceClient(\n",
    "  client_options=client_options,\n",
    ")\n",
    "# Build FindNeighborsRequest object\n",
    "datapoint = aiplatform_v1.IndexDatapoint(\n",
    "  feature_vector=test_embeddings\n",
    ")\n",
    "\n",
    "query = aiplatform_v1.FindNeighborsRequest.Query(\n",
    "  datapoint=datapoint,\n",
    "  # The number of nearest neighbors to be retrieved\n",
    "  neighbor_count=neighbor_count\n",
    ")\n",
    "\n",
    "request = aiplatform_v1.FindNeighborsRequest(\n",
    "  index_endpoint=INDEX_ENDPOINT,\n",
    "  deployed_index_id=DEPLOYED_INDEX_ID,\n",
    "  # Request can have multiple queries\n",
    "  queries=[query],\n",
    "  return_full_datapoint=False,\n",
    ")\n",
    "\n",
    "# Execute the request\n",
    "response = vector_search_client.find_neighbors(request)\n",
    "\n",
    "df_new = pd.DataFrame()\n",
    "# print('neighbor_count', neighbor_count)\n",
    "\n",
    "shots_df['distance'] = None\n",
    "\n",
    "for i in range(0,neighbor_count):\n",
    "    x=response.nearest_neighbors[0]\n",
    "\n",
    "    df_match = shots_df.loc[shots_df['id'] == int(x.neighbors[i].datapoint.datapoint_id) ]\n",
    "    df_match['distance'] = x.neighbors[i].distance\n",
    "\n",
    "    # Append the matching rows to the new DataFrame\n",
    "    df_new = pd.concat([df_new, df_match])\n",
    "    \n",
    "\n",
    "# Print the new DataFrame\n",
    "df_sorted = df_new.sort_values(by=\"distance\", ascending=True)\n",
    "display(df_sorted)\n",
    "\n",
    "#Export DataFrame to CSV file for reference\n",
    "df_new.to_csv(\"results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "3e4bf09e-68de-4c77-aad6-b6be9ced11fb",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for result in response.nearest_neighbors:\n",
    "    for neighbor in result.neighbors:\n",
    "        clip_id = int(neighbor.datapoint.datapoint_id)\n",
    "        distance = neighbor.distance\n",
    "        df_match = shots_df.loc[shots_df.index == clip_id]\n",
    "        if not df_match.empty:\n",
    "            match_info = df_match.iloc[0].to_dict()\n",
    "            match_info['distance'] = distance\n",
    "            results.append(match_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "d2a62998-8b5e-48e5-a951-2ac47c8bccbe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['content/clips/10 Sustainable Design and Infrastructure Features at Punggol Digital District_clip_2.mp4', 'content/clips/FIABCI delegates visit Punggol Digital District_clip_0.mp4', 'content/clips/FIABCI delegates visit Punggol Digital District_clip_1.mp4']\n"
     ]
    }
   ],
   "source": [
    "clipNames = []\n",
    "\n",
    "for i in df_sorted['clip_name']:\n",
    "    clipNames.append(i)\n",
    "    \n",
    "#Display the clips     \n",
    "print(clipNames)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c206cddf-9022-43a1-b0e3-bbbad439bb88",
   "metadata": {},
   "source": [
    "### Display Top 3 Relevant Clips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "56918019-cd58-4329-b6bb-4eea1bfc224b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"content/clips/10 Sustainable Design and Infrastructure Features at Punggol Digital District_clip_2.mp4\" controls  width=\"600\" >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<video src=\"content/clips/FIABCI delegates visit Punggol Digital District_clip_0.mp4\" controls  width=\"600\" >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<video src=\"content/clips/FIABCI delegates visit Punggol Digital District_clip_1.mp4\" controls  width=\"600\" >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import IPython\n",
    "\n",
    "for i in clipNames:\n",
    "    IPython.display.display(IPython.display.Video(i, width=600))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "45df467d-ff6a-47e6-a84d-7908c2af07bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "PROJECT_ID = !(gcloud config get-value core/project)\n",
    "PROJECT_ID = PROJECT_ID[0]\n",
    "\n",
    "SVC_ACC = !(gcloud config get-value core/account)\n",
    "SVC_ACC = SVC_ACC[0]\n",
    "\n",
    "PROJECT_NUMBER=str(re.search(r'\\d+', SVC_ACC).group())\n",
    "\n",
    "FOLDER_NAME=\".\"\n",
    "\n",
    "dataset_id = \"video_rag_dataset\"\n",
    "table_id = \"video_embeddings\"\n",
    "LOCATION=\"us-central1\"\n",
    "# full_table_id = '.'.join([PROJECT_ID,dataset_id,table_id])\n",
    "file_path = \"videodata.json\"\n",
    "\n",
    "\n",
    "from google.cloud import bigquery\n",
    "client = bigquery.Client(project=PROJECT_ID)\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "acf91bbd-ee84-4ad2-bf74-ccee45f66811",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_bigquery_dataset():\n",
    "    dataset = client.dataset(dataset_id)\n",
    "    dataset = client.create_dataset(dataset, timeout=30)  # Make an API request.\n",
    "    print(\"Created dataset {}.{}\".format(client.project, dataset.dataset_id))\n",
    "\n",
    "def create_bigquery_table():    \n",
    "    # Define the schema for the table\n",
    "    schema = [\n",
    "        bigquery.SchemaField(\"id\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"video_id\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"video_title\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"start_time\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"end_time\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"clip_name\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"frame_name\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"associated_text\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"associated_speech\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"associated_object\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"description\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"embedding\", \"FLOAT\", mode=\"REPEATED\")\n",
    "    ]\n",
    "    \n",
    "    # Define the table reference\n",
    "    table_ref = client.dataset(dataset_id).table(table_id)\n",
    "    \n",
    "    # Define the table object\n",
    "    table = bigquery.Table(table_ref, schema=schema)\n",
    "    \n",
    "    # Create the table in BigQuery\n",
    "    try:\n",
    "        client.create_table(table)\n",
    "        print(\"Table created successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating table: {e}\")\n",
    "\n",
    "def load_data_into_bigquery_table():\n",
    "    job_config = bigquery.LoadJobConfig(\n",
    "        source_format=bigquery.SourceFormat.NEWLINE_DELIMITED_JSON, autodetect=False)\n",
    "    \n",
    "    table_ref = client.dataset(dataset_id).table(table_id)\n",
    "    \n",
    "    with open(file_path, \"rb\") as source_file:\n",
    "        job = client.load_table_from_file(source_file, table_ref, job_config=job_config)\n",
    "    \n",
    "    job.result()  # Waits for the job to complete.\n",
    "    \n",
    "    table = client.get_table(table_ref)  # Make an API request.\n",
    "    print(\"Loaded {} rows and {} columns to {}\".format(\n",
    "        table.num_rows, len(table.schema), table_ref))\n",
    "    \n",
    "def read_bq_table_dataframe():  \n",
    "    table_ref = client.dataset(dataset_id).table(table_id)\n",
    "    dataframe = client.list_rows(table_ref).to_dataframe(create_bqstorage_client=True)\n",
    "    \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "f55fb03b-7402-415d-b2b0-e4042d854487",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created dataset ai-sb-test.video_rag_dataset\n",
      "Table created successfully.\n",
      "Loaded 20 rows and 12 columns to ai-sb-test.video_rag_dataset.video_embeddings\n"
     ]
    }
   ],
   "source": [
    "# Call the function to create the table\n",
    "create_bigquery_dataset()\n",
    "create_bigquery_table()\n",
    "load_data_into_bigquery_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ea69d483-fd8d-42af-aec1-5eb75238653d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>video_id</th>\n",
       "      <th>video_title</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>clip_name</th>\n",
       "      <th>frame_name</th>\n",
       "      <th>associated_text</th>\n",
       "      <th>associated_speech</th>\n",
       "      <th>associated_object</th>\n",
       "      <th>description</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>Open Digital Platform A smart district operati...</td>\n",
       "      <td>0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>content/clips/Open Digital Platform A smart di...</td>\n",
       "      <td>content/frames/frame_0.png</td>\n",
       "      <td>Security Counter\\nOur digital landscape is pow...</td>\n",
       "      <td>Our digital landscape is powered by data.\\nAnd...</td>\n",
       "      <td>Here is a description of the people in the vid...</td>\n",
       "      <td>Here is a description of the video in chronolo...</td>\n",
       "      <td>[0.0234115887, 0.0205032062, -0.0235713497, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>FIABCI delegates visit Punggol Digital District</td>\n",
       "      <td>0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>content/clips/FIABCI delegates visit Punggol D...</td>\n",
       "      <td>content/frames/frame_0.png</td>\n",
       "      <td>Here is a listing of all the text visible in t...</td>\n",
       "      <td>Here's a transcription of the audio from the p...</td>\n",
       "      <td>Here is a description of the people in the pro...</td>\n",
       "      <td>Here is a description of the video in chronolo...</td>\n",
       "      <td>[0.0137926154, 0.0141852899, -0.0281700697, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>JID Day Insights Pushing the Boundaries of Sus...</td>\n",
       "      <td>0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>content/clips/JID Day Insights Pushing the Bou...</td>\n",
       "      <td>content/frames/frame_0.png</td>\n",
       "      <td>Here is a list of the text visible in the vide...</td>\n",
       "      <td>My name is Praveen Hassan Chandrashekhar. I'm ...</td>\n",
       "      <td>The video shows one person:\\n\\nPraveen Hassan ...</td>\n",
       "      <td>Here is a description of the video in chronolo...</td>\n",
       "      <td>[-0.0067363228, -0.0022997283, -0.0177673753, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>10 Sustainable Design and Infrastructure Featu...</td>\n",
       "      <td>0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>content/clips/10 Sustainable Design and Infras...</td>\n",
       "      <td>content/frames/frame_0.png</td>\n",
       "      <td>Here is a list of the text visible in the vide...</td>\n",
       "      <td>Punggol Digital District is Singapore's first ...</td>\n",
       "      <td>Here is a description of the people in the vid...</td>\n",
       "      <td>Here is a description of the video in chronolo...</td>\n",
       "      <td>[-0.0081472127, -0.0133477803, -0.0354543589, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>8 hours of work done in just 2.5 hours Thats t...</td>\n",
       "      <td>0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>content/clips/8 hours of work done in just 2.5...</td>\n",
       "      <td>content/frames/frame_0.png</td>\n",
       "      <td>Here is a list of the text visible in the vide...</td>\n",
       "      <td>Here's a transcription of the audio from the v...</td>\n",
       "      <td>Here is a description of the people in the vid...</td>\n",
       "      <td>Here is a description of the video in chronolo...</td>\n",
       "      <td>[0.0193700604, 0.0265663471, -0.039097216, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>Whats Happening at SWITCH  onenorth</td>\n",
       "      <td>0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>content/clips/Whats Happening at SWITCH  oneno...</td>\n",
       "      <td>content/frames/frame_0.png</td>\n",
       "      <td>Here is a list of the text visible in the vide...</td>\n",
       "      <td>Alright, is this the right spot?\\n\\nCan I star...</td>\n",
       "      <td>Here is a description of the people and animal...</td>\n",
       "      <td>Here is a description of the video in chronolo...</td>\n",
       "      <td>[-0.0022940466, -0.0116759641, -0.0432454385, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>Punggol Digital District The future is yours t...</td>\n",
       "      <td>0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>content/clips/Punggol Digital District The fut...</td>\n",
       "      <td>content/frames/frame_0.png</td>\n",
       "      <td>THE FU\\nTHE FUTURE IS\\nTHE FUTURE IS YOURS TO\\...</td>\n",
       "      <td>Here is a transcription of the audio from the ...</td>\n",
       "      <td>Here is a description of the people and animal...</td>\n",
       "      <td>Here is a description of the video in chronolo...</td>\n",
       "      <td>[-0.0100430017, 0.0097944997, -0.0406552441, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Open Digital Platform A smart district operati...</td>\n",
       "      <td>60</td>\n",
       "      <td>120.0</td>\n",
       "      <td>content/clips/Open Digital Platform A smart di...</td>\n",
       "      <td>content/frames/frame_1.png</td>\n",
       "      <td>Here is a list of the text visible in the vide...</td>\n",
       "      <td>Developed by JTC and GovTech, in collaboration...</td>\n",
       "      <td>Here is a description of the people in the vid...</td>\n",
       "      <td>Here is a description of the video in chronolo...</td>\n",
       "      <td>[0.0204791036, 0.0032895294, -0.0439610444, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>FIABCI delegates visit Punggol Digital District</td>\n",
       "      <td>60</td>\n",
       "      <td>91.32</td>\n",
       "      <td>content/clips/FIABCI delegates visit Punggol D...</td>\n",
       "      <td>content/frames/frame_1.png</td>\n",
       "      <td>Here is a list of the text visible in the vide...</td>\n",
       "      <td>of how to use the data to organise the living,...</td>\n",
       "      <td>Certainly, here is a description of the people...</td>\n",
       "      <td>Here is a description of the video in chronolo...</td>\n",
       "      <td>[0.0049185185, 0.0119622033, -0.0332286321, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>JID Day Insights Pushing the Boundaries of Sus...</td>\n",
       "      <td>60</td>\n",
       "      <td>120.0</td>\n",
       "      <td>content/clips/JID Day Insights Pushing the Bou...</td>\n",
       "      <td>content/frames/frame_1.png</td>\n",
       "      <td>Here is a transcription of the visible text in...</td>\n",
       "      <td>Here's a transcription of the audio from the p...</td>\n",
       "      <td>The video shows one person, a man who appears ...</td>\n",
       "      <td>Here is a description of the video in chronolo...</td>\n",
       "      <td>[-0.0045801108, -0.0206682421, -0.010879931, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>10 Sustainable Design and Infrastructure Featu...</td>\n",
       "      <td>60</td>\n",
       "      <td>120.0</td>\n",
       "      <td>content/clips/10 Sustainable Design and Infras...</td>\n",
       "      <td>content/frames/frame_1.png</td>\n",
       "      <td>Here is a listing of all the text visible in t...</td>\n",
       "      <td>Natural ventilation keeps selected areas cool ...</td>\n",
       "      <td>Here is a description of the people in the vid...</td>\n",
       "      <td>Here is a description of the video in chronolo...</td>\n",
       "      <td>[-0.0208292063, 0.0026199173, -0.0440339521, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>8 hours of work done in just 2.5 hours Thats t...</td>\n",
       "      <td>60</td>\n",
       "      <td>97.04</td>\n",
       "      <td>content/clips/8 hours of work done in just 2.5...</td>\n",
       "      <td>content/frames/frame_1.png</td>\n",
       "      <td>Here is a list of the text visible in the vide...</td>\n",
       "      <td>Here's a transcription of the audio from the v...</td>\n",
       "      <td>Here is a description of the people in the pro...</td>\n",
       "      <td>Here is a description of the video in chronolo...</td>\n",
       "      <td>[0.0369597301, 0.010101255, -0.0357092544, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>Whats Happening at SWITCH  onenorth</td>\n",
       "      <td>60</td>\n",
       "      <td>80.71</td>\n",
       "      <td>content/clips/Whats Happening at SWITCH  oneno...</td>\n",
       "      <td>content/frames/frame_1.png</td>\n",
       "      <td>Here is a list of the text visible in the vide...</td>\n",
       "      <td>What you're looking at over here are some 3D p...</td>\n",
       "      <td>Here is a description of the people in the pro...</td>\n",
       "      <td>Here is a description of the video provided.\\n...</td>\n",
       "      <td>[-0.000875177, -0.0053729322, -0.0344497338, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>17</td>\n",
       "      <td>7</td>\n",
       "      <td>Punggol Digital District The future is yours t...</td>\n",
       "      <td>60</td>\n",
       "      <td>120.0</td>\n",
       "      <td>content/clips/Punggol Digital District The fut...</td>\n",
       "      <td>content/frames/frame_1.png</td>\n",
       "      <td>Here is a listing of the text visible in the v...</td>\n",
       "      <td>Tech companies can plug into this virtual worl...</td>\n",
       "      <td>Here is a description of the people in the vid...</td>\n",
       "      <td>Here is a description of the video in chronolo...</td>\n",
       "      <td>[0.0373544283, 0.0215301886, -0.0415258929, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Open Digital Platform A smart district operati...</td>\n",
       "      <td>120</td>\n",
       "      <td>180.0</td>\n",
       "      <td>content/clips/Open Digital Platform A smart di...</td>\n",
       "      <td>content/frames/frame_2.png</td>\n",
       "      <td>Here is a list of the text visible in the vide...</td>\n",
       "      <td>the platform can then tap on these data sets f...</td>\n",
       "      <td>Here is a description of the people in the pro...</td>\n",
       "      <td>Here is a description of the video in chronolo...</td>\n",
       "      <td>[-0.0195334535, 0.0030750451, -0.0451132469, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>JID Day Insights Pushing the Boundaries of Sus...</td>\n",
       "      <td>120</td>\n",
       "      <td>180.0</td>\n",
       "      <td>content/clips/JID Day Insights Pushing the Bou...</td>\n",
       "      <td>content/frames/frame_2.png</td>\n",
       "      <td>The following is a list of the text visible in...</td>\n",
       "      <td>Here's a transcription of the audio from the p...</td>\n",
       "      <td>Here is a description of the people in the pro...</td>\n",
       "      <td>Here is a description of the video in chronolo...</td>\n",
       "      <td>[0.0053725676, -0.0086990921, -0.0092547378, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>10 Sustainable Design and Infrastructure Featu...</td>\n",
       "      <td>120</td>\n",
       "      <td>157.18</td>\n",
       "      <td>content/clips/10 Sustainable Design and Infras...</td>\n",
       "      <td>content/frames/frame_2.png</td>\n",
       "      <td>Here is a listing of all the text visible in t...</td>\n",
       "      <td>Certainly! Here is a transcription of the audi...</td>\n",
       "      <td>Here is a description of the people and animal...</td>\n",
       "      <td>Here is a description of the video in chronolo...</td>\n",
       "      <td>[-0.0026686555, -0.001852289, -0.0519292206, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "      <td>Punggol Digital District The future is yours t...</td>\n",
       "      <td>120</td>\n",
       "      <td>133.45</td>\n",
       "      <td>content/clips/Punggol Digital District The fut...</td>\n",
       "      <td>content/frames/frame_2.png</td>\n",
       "      <td>Here is a list of the text visible in the vide...</td>\n",
       "      <td>the future is yours to discover, yours to imag...</td>\n",
       "      <td>Here is a description of the people in the pro...</td>\n",
       "      <td>Here is a description of the video provided.\\n...</td>\n",
       "      <td>[0.0100940587, 0.0080087474, -0.0197473317, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Open Digital Platform A smart district operati...</td>\n",
       "      <td>180</td>\n",
       "      <td>186.36</td>\n",
       "      <td>content/clips/Open Digital Platform A smart di...</td>\n",
       "      <td>content/frames/frame_3.png</td>\n",
       "      <td>Here's a list of the text visible in the video...</td>\n",
       "      <td>Here's a transcription of the audio from the p...</td>\n",
       "      <td>There are no people or animals in this video.</td>\n",
       "      <td>The video begins with a QR code and a website ...</td>\n",
       "      <td>[-0.0063041924, -0.0065677841, -0.0591881424, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>JID Day Insights Pushing the Boundaries of Sus...</td>\n",
       "      <td>180</td>\n",
       "      <td>209.86</td>\n",
       "      <td>content/clips/JID Day Insights Pushing the Bou...</td>\n",
       "      <td>content/frames/frame_3.png</td>\n",
       "      <td>Here is a list of the text visible in the vide...</td>\n",
       "      <td>Here's a transcription of the audio from the v...</td>\n",
       "      <td>Here is a description of the people in the pro...</td>\n",
       "      <td>Here is a description of the video in chronolo...</td>\n",
       "      <td>[0.0191108081, 0.0034572412, -0.0088915685, 0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id video_id                                        video_title start_time  \\\n",
       "0   -1        1  Open Digital Platform A smart district operati...          0   \n",
       "1    3        2    FIABCI delegates visit Punggol Digital District          0   \n",
       "2    5        3  JID Day Insights Pushing the Boundaries of Sus...          0   \n",
       "3    9        4  10 Sustainable Design and Infrastructure Featu...          0   \n",
       "4   12        5  8 hours of work done in just 2.5 hours Thats t...          0   \n",
       "5   14        6                Whats Happening at SWITCH  onenorth          0   \n",
       "6   16        7  Punggol Digital District The future is yours t...          0   \n",
       "7    0        1  Open Digital Platform A smart district operati...         60   \n",
       "8    4        2    FIABCI delegates visit Punggol Digital District         60   \n",
       "9    6        3  JID Day Insights Pushing the Boundaries of Sus...         60   \n",
       "10  10        4  10 Sustainable Design and Infrastructure Featu...         60   \n",
       "11  13        5  8 hours of work done in just 2.5 hours Thats t...         60   \n",
       "12  15        6                Whats Happening at SWITCH  onenorth         60   \n",
       "13  17        7  Punggol Digital District The future is yours t...         60   \n",
       "14   1        1  Open Digital Platform A smart district operati...        120   \n",
       "15   7        3  JID Day Insights Pushing the Boundaries of Sus...        120   \n",
       "16  11        4  10 Sustainable Design and Infrastructure Featu...        120   \n",
       "17  18        7  Punggol Digital District The future is yours t...        120   \n",
       "18   2        1  Open Digital Platform A smart district operati...        180   \n",
       "19   8        3  JID Day Insights Pushing the Boundaries of Sus...        180   \n",
       "\n",
       "   end_time                                          clip_name  \\\n",
       "0      60.0  content/clips/Open Digital Platform A smart di...   \n",
       "1      60.0  content/clips/FIABCI delegates visit Punggol D...   \n",
       "2      60.0  content/clips/JID Day Insights Pushing the Bou...   \n",
       "3      60.0  content/clips/10 Sustainable Design and Infras...   \n",
       "4      60.0  content/clips/8 hours of work done in just 2.5...   \n",
       "5      60.0  content/clips/Whats Happening at SWITCH  oneno...   \n",
       "6      60.0  content/clips/Punggol Digital District The fut...   \n",
       "7     120.0  content/clips/Open Digital Platform A smart di...   \n",
       "8     91.32  content/clips/FIABCI delegates visit Punggol D...   \n",
       "9     120.0  content/clips/JID Day Insights Pushing the Bou...   \n",
       "10    120.0  content/clips/10 Sustainable Design and Infras...   \n",
       "11    97.04  content/clips/8 hours of work done in just 2.5...   \n",
       "12    80.71  content/clips/Whats Happening at SWITCH  oneno...   \n",
       "13    120.0  content/clips/Punggol Digital District The fut...   \n",
       "14    180.0  content/clips/Open Digital Platform A smart di...   \n",
       "15    180.0  content/clips/JID Day Insights Pushing the Bou...   \n",
       "16   157.18  content/clips/10 Sustainable Design and Infras...   \n",
       "17   133.45  content/clips/Punggol Digital District The fut...   \n",
       "18   186.36  content/clips/Open Digital Platform A smart di...   \n",
       "19   209.86  content/clips/JID Day Insights Pushing the Bou...   \n",
       "\n",
       "                    frame_name  \\\n",
       "0   content/frames/frame_0.png   \n",
       "1   content/frames/frame_0.png   \n",
       "2   content/frames/frame_0.png   \n",
       "3   content/frames/frame_0.png   \n",
       "4   content/frames/frame_0.png   \n",
       "5   content/frames/frame_0.png   \n",
       "6   content/frames/frame_0.png   \n",
       "7   content/frames/frame_1.png   \n",
       "8   content/frames/frame_1.png   \n",
       "9   content/frames/frame_1.png   \n",
       "10  content/frames/frame_1.png   \n",
       "11  content/frames/frame_1.png   \n",
       "12  content/frames/frame_1.png   \n",
       "13  content/frames/frame_1.png   \n",
       "14  content/frames/frame_2.png   \n",
       "15  content/frames/frame_2.png   \n",
       "16  content/frames/frame_2.png   \n",
       "17  content/frames/frame_2.png   \n",
       "18  content/frames/frame_3.png   \n",
       "19  content/frames/frame_3.png   \n",
       "\n",
       "                                      associated_text  \\\n",
       "0   Security Counter\\nOur digital landscape is pow...   \n",
       "1   Here is a listing of all the text visible in t...   \n",
       "2   Here is a list of the text visible in the vide...   \n",
       "3   Here is a list of the text visible in the vide...   \n",
       "4   Here is a list of the text visible in the vide...   \n",
       "5   Here is a list of the text visible in the vide...   \n",
       "6   THE FU\\nTHE FUTURE IS\\nTHE FUTURE IS YOURS TO\\...   \n",
       "7   Here is a list of the text visible in the vide...   \n",
       "8   Here is a list of the text visible in the vide...   \n",
       "9   Here is a transcription of the visible text in...   \n",
       "10  Here is a listing of all the text visible in t...   \n",
       "11  Here is a list of the text visible in the vide...   \n",
       "12  Here is a list of the text visible in the vide...   \n",
       "13  Here is a listing of the text visible in the v...   \n",
       "14  Here is a list of the text visible in the vide...   \n",
       "15  The following is a list of the text visible in...   \n",
       "16  Here is a listing of all the text visible in t...   \n",
       "17  Here is a list of the text visible in the vide...   \n",
       "18  Here's a list of the text visible in the video...   \n",
       "19  Here is a list of the text visible in the vide...   \n",
       "\n",
       "                                    associated_speech  \\\n",
       "0   Our digital landscape is powered by data.\\nAnd...   \n",
       "1   Here's a transcription of the audio from the p...   \n",
       "2   My name is Praveen Hassan Chandrashekhar. I'm ...   \n",
       "3   Punggol Digital District is Singapore's first ...   \n",
       "4   Here's a transcription of the audio from the v...   \n",
       "5   Alright, is this the right spot?\\n\\nCan I star...   \n",
       "6   Here is a transcription of the audio from the ...   \n",
       "7   Developed by JTC and GovTech, in collaboration...   \n",
       "8   of how to use the data to organise the living,...   \n",
       "9   Here's a transcription of the audio from the p...   \n",
       "10  Natural ventilation keeps selected areas cool ...   \n",
       "11  Here's a transcription of the audio from the v...   \n",
       "12  What you're looking at over here are some 3D p...   \n",
       "13  Tech companies can plug into this virtual worl...   \n",
       "14  the platform can then tap on these data sets f...   \n",
       "15  Here's a transcription of the audio from the p...   \n",
       "16  Certainly! Here is a transcription of the audi...   \n",
       "17  the future is yours to discover, yours to imag...   \n",
       "18  Here's a transcription of the audio from the p...   \n",
       "19  Here's a transcription of the audio from the v...   \n",
       "\n",
       "                                    associated_object  \\\n",
       "0   Here is a description of the people in the vid...   \n",
       "1   Here is a description of the people in the pro...   \n",
       "2   The video shows one person:\\n\\nPraveen Hassan ...   \n",
       "3   Here is a description of the people in the vid...   \n",
       "4   Here is a description of the people in the vid...   \n",
       "5   Here is a description of the people and animal...   \n",
       "6   Here is a description of the people and animal...   \n",
       "7   Here is a description of the people in the vid...   \n",
       "8   Certainly, here is a description of the people...   \n",
       "9   The video shows one person, a man who appears ...   \n",
       "10  Here is a description of the people in the vid...   \n",
       "11  Here is a description of the people in the pro...   \n",
       "12  Here is a description of the people in the pro...   \n",
       "13  Here is a description of the people in the vid...   \n",
       "14  Here is a description of the people in the pro...   \n",
       "15  Here is a description of the people in the pro...   \n",
       "16  Here is a description of the people and animal...   \n",
       "17  Here is a description of the people in the pro...   \n",
       "18      There are no people or animals in this video.   \n",
       "19  Here is a description of the people in the pro...   \n",
       "\n",
       "                                          description  \\\n",
       "0   Here is a description of the video in chronolo...   \n",
       "1   Here is a description of the video in chronolo...   \n",
       "2   Here is a description of the video in chronolo...   \n",
       "3   Here is a description of the video in chronolo...   \n",
       "4   Here is a description of the video in chronolo...   \n",
       "5   Here is a description of the video in chronolo...   \n",
       "6   Here is a description of the video in chronolo...   \n",
       "7   Here is a description of the video in chronolo...   \n",
       "8   Here is a description of the video in chronolo...   \n",
       "9   Here is a description of the video in chronolo...   \n",
       "10  Here is a description of the video in chronolo...   \n",
       "11  Here is a description of the video in chronolo...   \n",
       "12  Here is a description of the video provided.\\n...   \n",
       "13  Here is a description of the video in chronolo...   \n",
       "14  Here is a description of the video in chronolo...   \n",
       "15  Here is a description of the video in chronolo...   \n",
       "16  Here is a description of the video in chronolo...   \n",
       "17  Here is a description of the video provided.\\n...   \n",
       "18  The video begins with a QR code and a website ...   \n",
       "19  Here is a description of the video in chronolo...   \n",
       "\n",
       "                                            embedding  \n",
       "0   [0.0234115887, 0.0205032062, -0.0235713497, 0....  \n",
       "1   [0.0137926154, 0.0141852899, -0.0281700697, 0....  \n",
       "2   [-0.0067363228, -0.0022997283, -0.0177673753, ...  \n",
       "3   [-0.0081472127, -0.0133477803, -0.0354543589, ...  \n",
       "4   [0.0193700604, 0.0265663471, -0.039097216, 0.0...  \n",
       "5   [-0.0022940466, -0.0116759641, -0.0432454385, ...  \n",
       "6   [-0.0100430017, 0.0097944997, -0.0406552441, 0...  \n",
       "7   [0.0204791036, 0.0032895294, -0.0439610444, 0....  \n",
       "8   [0.0049185185, 0.0119622033, -0.0332286321, 0....  \n",
       "9   [-0.0045801108, -0.0206682421, -0.010879931, 0...  \n",
       "10  [-0.0208292063, 0.0026199173, -0.0440339521, 0...  \n",
       "11  [0.0369597301, 0.010101255, -0.0357092544, -0....  \n",
       "12  [-0.000875177, -0.0053729322, -0.0344497338, -...  \n",
       "13  [0.0373544283, 0.0215301886, -0.0415258929, -0...  \n",
       "14  [-0.0195334535, 0.0030750451, -0.0451132469, 0...  \n",
       "15  [0.0053725676, -0.0086990921, -0.0092547378, 0...  \n",
       "16  [-0.0026686555, -0.001852289, -0.0519292206, -...  \n",
       "17  [0.0100940587, 0.0080087474, -0.0197473317, -0...  \n",
       "18  [-0.0063041924, -0.0065677841, -0.0591881424, ...  \n",
       "19  [0.0191108081, 0.0034572412, -0.0088915685, 0....  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe = read_bq_table_dataframe()\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc537471-3163-44d3-83b2-3212977e7419",
   "metadata": {},
   "source": [
    "## Querying using Gemini Model instead of Vector Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1db7cd-19c1-4134-bc3c-28647eac4501",
   "metadata": {},
   "source": [
    "### Defining Functions for Gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "56839314-719c-4171-8c36-0baaa1e20905",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import vertexai\n",
    "from vertexai.preview.generative_models import GenerativeModel, Part\n",
    "from vertexai.preview.language_models import TextGenerationModel\n",
    "\n",
    "def generate(input_prompt):\n",
    "    model = GenerativeModel(\"gemini-ultra\")\n",
    "    responses = model.generate_content(\n",
    "        input_prompt ,\n",
    "    generation_config={\n",
    "        \"max_output_tokens\": 2048,\n",
    "        \"temperature\": 0.2,\n",
    "        \"top_p\": 1,\n",
    "        \"top_k\": 32\n",
    "    },\n",
    "        safety_settings=[],\n",
    "        stream=True,\n",
    "    )\n",
    "    \n",
    "    all_response  = []\n",
    "    \n",
    "    for response in responses:\n",
    "        # print(response.text, end=\"\")\n",
    "        all_response.append(response.text)\n",
    "    \n",
    "    return(\" \".join(all_response))\n",
    "    \n",
    "\n",
    "def generate_pro(input_prompt):\n",
    "    model = GenerativeModel(\"gemini-1.5-flash-002\")\n",
    "    responses = model.generate_content(\n",
    "    input_prompt,\n",
    "    generation_config={\n",
    "        \"max_output_tokens\": 2048,\n",
    "        \"temperature\": 0.2,\n",
    "        \"top_p\": 1\n",
    "    },stream=True,)\n",
    "    \n",
    "    all_response  = []\n",
    "    \n",
    "    for response in responses:\n",
    "        all_response.append(response.text)\n",
    "\n",
    "    return(\" \".join(all_response))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df08a0c-434b-4040-a830-b3d775ce774a",
   "metadata": {},
   "source": [
    "### Query using Gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "ed3ccae4-1c2f-4a67-b11d-ac7dc50fa206",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Insert with your own query\n",
    "query = \"Summarise the PDD project\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "7a7a30fb-e0eb-4847-997e-065114ebca8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def combine_column_to_string(df, column_name):\n",
    "\n",
    "    column_values = df[column_name].tolist()\n",
    "    combined_string = ', '.join(column_values)\n",
    "    return combined_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "8df35b3e-6305-4d23-8ee2-b4bc75ae0a0f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>video_id</th>\n",
       "      <th>video_title</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>clip_name</th>\n",
       "      <th>frame_name</th>\n",
       "      <th>associated_text</th>\n",
       "      <th>associated_speech</th>\n",
       "      <th>associated_object</th>\n",
       "      <th>description</th>\n",
       "      <th>embedding</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>FIABCI delegates visit Punggol Digital District</td>\n",
       "      <td>60</td>\n",
       "      <td>91.32</td>\n",
       "      <td>content/clips/FIABCI delegates visit Punggol D...</td>\n",
       "      <td>content/frames/frame_1.png</td>\n",
       "      <td>Here is a list of the text visible in the vide...</td>\n",
       "      <td>of how to use the data to organise the living,...</td>\n",
       "      <td>Certainly, here is a description of the people...</td>\n",
       "      <td>Here is a description of the video in chronolo...</td>\n",
       "      <td>[0.004918518476188183, 0.011962203308939934, -...</td>\n",
       "      <td>0.669026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>FIABCI delegates visit Punggol Digital District</td>\n",
       "      <td>0</td>\n",
       "      <td>60.00</td>\n",
       "      <td>content/clips/FIABCI delegates visit Punggol D...</td>\n",
       "      <td>content/frames/frame_0.png</td>\n",
       "      <td>Here is a listing of all the text visible in t...</td>\n",
       "      <td>Here's a transcription of the audio from the p...</td>\n",
       "      <td>Here is a description of the people in the pro...</td>\n",
       "      <td>Here is a description of the video in chronolo...</td>\n",
       "      <td>[0.013792615383863449, 0.014185289852321148, -...</td>\n",
       "      <td>0.665848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>10 Sustainable Design and Infrastructure Featu...</td>\n",
       "      <td>120</td>\n",
       "      <td>157.18</td>\n",
       "      <td>content/clips/10 Sustainable Design and Infras...</td>\n",
       "      <td>content/frames/frame_2.png</td>\n",
       "      <td>Here is a listing of all the text visible in t...</td>\n",
       "      <td>Certainly! Here is a transcription of the audi...</td>\n",
       "      <td>Here is a description of the people and animal...</td>\n",
       "      <td>Here is a description of the video in chronolo...</td>\n",
       "      <td>[-0.002668655477464199, -0.0018522889586165547...</td>\n",
       "      <td>0.632236</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  id  video_id  \\\n",
       "0           5   4         2   \n",
       "1           4   3         2   \n",
       "2          12  11         4   \n",
       "\n",
       "                                         video_title  start_time  end_time  \\\n",
       "0    FIABCI delegates visit Punggol Digital District          60     91.32   \n",
       "1    FIABCI delegates visit Punggol Digital District           0     60.00   \n",
       "2  10 Sustainable Design and Infrastructure Featu...         120    157.18   \n",
       "\n",
       "                                           clip_name  \\\n",
       "0  content/clips/FIABCI delegates visit Punggol D...   \n",
       "1  content/clips/FIABCI delegates visit Punggol D...   \n",
       "2  content/clips/10 Sustainable Design and Infras...   \n",
       "\n",
       "                   frame_name  \\\n",
       "0  content/frames/frame_1.png   \n",
       "1  content/frames/frame_0.png   \n",
       "2  content/frames/frame_2.png   \n",
       "\n",
       "                                     associated_text  \\\n",
       "0  Here is a list of the text visible in the vide...   \n",
       "1  Here is a listing of all the text visible in t...   \n",
       "2  Here is a listing of all the text visible in t...   \n",
       "\n",
       "                                   associated_speech  \\\n",
       "0  of how to use the data to organise the living,...   \n",
       "1  Here's a transcription of the audio from the p...   \n",
       "2  Certainly! Here is a transcription of the audi...   \n",
       "\n",
       "                                   associated_object  \\\n",
       "0  Certainly, here is a description of the people...   \n",
       "1  Here is a description of the people in the pro...   \n",
       "2  Here is a description of the people and animal...   \n",
       "\n",
       "                                         description  \\\n",
       "0  Here is a description of the video in chronolo...   \n",
       "1  Here is a description of the video in chronolo...   \n",
       "2  Here is a description of the video in chronolo...   \n",
       "\n",
       "                                           embedding  distance  \n",
       "0  [0.004918518476188183, 0.011962203308939934, -...  0.669026  \n",
       "1  [0.013792615383863449, 0.014185289852321148, -...  0.665848  \n",
       "2  [-0.002668655477464199, -0.0018522889586165547...  0.632236  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "shots_df = pd.read_csv('./results.csv') \n",
    "shots_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "0737729f-cbff-4d4c-9f1a-186ffc6d14a7",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your prompt: \n",
      " You are an expert in screening video descriptions and understanding the context and contents of the video.\n",
      "Only answer based on the description of the video provided here: \n",
      " Here is a description of the video in chronological order:\n",
      "\n",
      "The video opens with a woman speaking. She is standing in front of a large screen displaying an image of a city and the words, Singapores Most Highly Anticipated Smart District. She discusses how data is used to organize living and working spaces, and to determine how people spend their time in the district.\n",
      "\n",
      "Next, a pop-up box appears on the screen, asking, Switch off lights and AC? with Yes and No options. Then, two graphs appear, showing data on cooling tower fan speed and total power saved. The numbers on the graphs change, indicating energy savings.\n",
      "\n",
      "A man is then shown speaking. He is identified as Lszl Gnczi from FIABCI Hungary. He comments on the masterplan for the district, noting that it is very nice and includes a lot of greenery. He then points out that when buildings are constructed, there are a lot of amenities for the people, allowing for a good quality of life.\n",
      "\n",
      "The video then shows a model of the district, followed by images of informational posters about the Punggol Digital District. The posters highlight the districts amenities and transportation links.\n",
      "\n",
      "Finally, the video ends with the logos of Building Industries and JTC., Here is a description of the video in chronological order:\n",
      "\n",
      "The video opens with a graphic that reads Punggol Digital District, Singapores Most Highly Anticipated Smart District.\n",
      "\n",
      "A man, identified as Jake Caine of FIABCI Australia, speaks to the camera. He says that coming from Australia, where they are experiencing a severe housing crisis, he is impressed by the smart and sustainable building community and new university being developed in Singapores Punggol Digital District.\n",
      "\n",
      "The video then shows a group of people looking at a large architectural model of the Punggol Digital District.\n",
      "\n",
      "Next, there is a shot of a modern building with a skywalk.\n",
      "\n",
      "Mr. Caine speaks again, reiterating his amazement at the new university.\n",
      "\n",
      "A presentation slide shows an image of the Heart of PDD, which includes a large open space with retail and dining options.\n",
      "\n",
      "A woman in a lime green safety vest leads a group of people wearing hard hats and safety vests on a tour of a building under construction.\n",
      "\n",
      "Antonio Campagnoli of FIABCI Italy is shown speaking to the camera. He says that the Punggol Digital District is a wonderful example of how to enhance the connection between communities.\n",
      "\n",
      "A woman in a dark polo shirt gives a presentation to a group of people in front of an architectural model.\n",
      "\n",
      "Mr. Campagnoli speaks again, saying that he loves the projects focus on creating a community, fostering interaction among companies, and finding talent.\n",
      "\n",
      "David Steiner of FIABCI Austria is shown speaking to the camera. He says that he likes how the project incorporates air conditioning with the natural winds, using a north-south building orientation to reduce energy consumption.\n",
      "\n",
      "The video shows close-up shots of smart meters and air quality monitoring equipment.\n",
      "\n",
      "More shots of the architectural model are shown.\n",
      "\n",
      "Mr. Steiner speaks again, emphasizing the energy efficiency of the building design.\n",
      "\n",
      "Alissa Bankovska of FIABCI Italy is shown speaking to the camera. She says that she is very impressed with the smart district, especially the use of data to organize living.\n",
      "\n",
      "The video ends with a shot of informational graphics about the Punggol Digital District., Here is a description of the video in chronological order:\n",
      "\n",
      "The video opens with an animation of a wireframe building. A blue line extends from the building to a blue box, which is labeled Pneumatic Waste Conveyance System. The narrator explains that the system monitors waste collection and transfers it underground, creating a better working environment.\n",
      "\n",
      "Next, the video shows a person walking down a cobblestone street carrying three reusable shopping bags.\n",
      "\n",
      "The animation of the wireframe building reappears. This time, a blue line extends from the building to a blue pool of water. The text Rainwater Harvesting and Reduction in Reliance on Potable Water appear on the screen. The narrator explains that rainwater is filtered through rain gardens and eco-ponds and collected to irrigate green spaces.\n",
      "\n",
      "The video then shows footage of a pond with aquatic plants, a close-up of a drip irrigation system watering a plant, and an animation of a modern building with green spaces and people walking around.\n",
      "\n",
      "The narrator explains that through sustainable design, energy optimization using smart technology, and clean energy use, a net-zero future is possible.\n",
      "\n",
      "The video concludes with an aerial shot of Punggol Digital District at night, followed by the logos for Building Industries and JTC.Here is a list of the text visible in the video provided, in chronological order:\n",
      "\n",
      "SINGAPORES MOST HIGHLY\n",
      "ANTICIPATED SMART DISTRICT\n",
      "\n",
      "of how to use the data to organise the living,\n",
      "the working, how people spend time here,\n",
      "in the best, the most comfortable way.\n",
      "\n",
      "Switch off lights and AC?\n",
      "YES     NO\n",
      "\n",
      "Cooling Tower Fan Speed\n",
      "21.39%\n",
      "SMART C\n",
      "\n",
      "Cooling Tower Fan Speed\n",
      "33.17%\n",
      "Total Power Saved\n",
      "7.500 KW\n",
      "SMART AND SUSTAINABLE\n",
      "ESTATE SOLUTIONS.\n",
      "Total Power Saved\n",
      "15.312 KW\n",
      "\n",
      "LSZL GNCZI | FIABCI Hungary\n",
      "\n",
      "The masterplan, we have seen, its very nice,\n",
      "very good, with a lot of greenery.\n",
      "\n",
      "But what is interesting here, that when you are constructing buildings,\n",
      "\n",
      "NE18 Punggol Coast Station\n",
      "The new Punggol Coast MRT station is a collaboration between LTA and JTC.\n",
      "The station is architecturally and structurally integrated with the Punggol\n",
      "Digital District (PDD) development. Upon completion of the C715 tunnelling\n",
      "works, the tunnel boring machines would break through at the Receiving Shaft\n",
      "within PDD. This will mark the official connection between the existing\n",
      "Punggol MRT station and PDD development.\n",
      "LEGEND\n",
      "\n",
      "But what is interesting here, that when you are constructing buildings,\n",
      "\n",
      "Everyone is\n",
      "welcome at\n",
      "Punggol Digital\n",
      "District\n",
      "PDD is connected to the rest of Singapore by\n",
      "expressways, an upcoming integrated bus interchange,\n",
      "as well as the future Punggol Coast MRT station. It is a\n",
      "short drive to Changi Airport, Seletar Airport and the\n",
      "Central Business District.\n",
      "Besides PDDs proximity to existing destinations such as\n",
      "Punggol Promenade and Coney Island, new amenities\n",
      "such as childcare centres, hawker centre and a\n",
      "community club make it a one-stop hub that fully\n",
      "embodies the live-work-learn-play lifestyle.\n",
      "\n",
      "allowing for a really good life when they are at home.\n",
      "\n",
      "So, congratulations.\n",
      "\n",
      "BUILDING INDUSTRIES \n",
      "\n",
      "jtc, Here is a listing of all the text visible in the provided video, in chronological order:\n",
      "\n",
      "punggol\n",
      "digital\n",
      "district\n",
      "\n",
      "SINGAPORE'S MOST HIGHLY\n",
      "ANTICIPATED SMART DISTRICT\n",
      "\n",
      "JAKE CAINE | FIABCI Australia\n",
      "\n",
      "jtc\n",
      "\n",
      "the delivery of a smart and sustainable building community\n",
      "\n",
      "and a new university is incredible to witness.\n",
      "\n",
      "Heart of PDD\n",
      "Nexus, Events, MRT\n",
      "\n",
      " Retail and dining options\n",
      "serving the workers,\n",
      "students, residents and\n",
      "visitors\n",
      "\n",
      " Plaza designed for place-\n",
      "making activities\n",
      "\n",
      "The PDD is a wonderful example of how you\n",
      "\n",
      "ANTONIO CAMPAGNOLI | FIABCI Italy\n",
      "\n",
      "What I really love about this project is your desire to make\n",
      "\n",
      "punggol\n",
      "digital\n",
      "district\n",
      "\n",
      "a community, to make interaction among the companies, to find talent.\n",
      "\n",
      "DAVID STEINER | FIABCI Austria\n",
      "\n",
      "* Air Quality\n",
      "Monitoring\n",
      "\n",
      "* Energy\n",
      "Monitoring\n",
      "\n",
      "Indoor Air Quality Monitor\n",
      "\n",
      "Smart Meters\n",
      "\n",
      "Air Condition\n",
      "System Con\n",
      "\n",
      "Pump/Ventilation\n",
      "Chiller/\n",
      "Air Conditioning\n",
      "\n",
      "with the winds which are going through the (north-south orientation of the) buildings,\n",
      "\n",
      "that you're building it like this, to use less of the energy.\n",
      "\n",
      "ALISSA BANKOVSKA | FIABCI Italy\n",
      "\n",
      "SINGAPORE'S MOST HIGHLY\n",
      "ANTICIPATED SMART DISTRICT\n",
      "\n",
      "Small issues\n",
      "never become\n",
      "big, thanks\n",
      "to big data\n",
      "\n",
      "Powered by a network of smart sensors, the\n",
      "Digital Platform (SDP) by JTC, GovTech and the\n",
      "Engineering, Building and Construction Authority\n",
      "monitors and manages the district's electrical, cooling and\n",
      "waste systems.\n",
      "\n",
      "Estate operators can optimize resources through\n",
      "real-time data to run their buildings better. With\n",
      "insights from data analytics, they can better\n",
      "recognize issues, create better lighting and air\n",
      "conditioning schemes and optimize traffic flow. With data\n",
      "analytics, they can discover what went wrong\n",
      "before it happens.\n",
      "\n",
      "Digitally planned\n",
      "from the\n",
      "ground up\n",
      "\n",
      "First of all, because of the data, because of the understanding, Here is a listing of all the text visible in the video provided:\n",
      "\n",
      "PNEUMATIC WASTE\n",
      "CONVEYANCE SYSTEM\n",
      "equipped with sensors monitors waste collection and transfers them underground, creating a better working environment for all.\n",
      "\n",
      "RAINWATER HARVESTING\n",
      "REDUCTION IN RELIANCE ON POTABLE WATER\n",
      "rainwater filtered through rain gardens and eco-ponds, are collected to irrigate green spaces.\n",
      "\n",
      "Through sustainable design, energy optimisation using smart technology, and clean energy use, a net zero future is yours to create, here at Punggol Digital District.\n",
      "\n",
      "BUILDING INDUSTRIES (SG)\n",
      "\n",
      "jtcof how to use the data to organise the living, the working, the spending time here, in the best, the most comfortable way. The masterplan, we have seen, it's very nice, very good, with a lot of greenery. But what is interesting here, that when you are constructing buildings, there are a lot of amenities for the people, allowing for a really good life when they are at home. So, congratulations., Here's a transcription of the audio from the provided video:\n",
      "\n",
      "Well, coming from Australia, where we're in the midst of perhaps the most acute housing supply and affordability crisis that we've ever been through, to see what is happening here, the delivery of a smart and sustainable building community and a new university is incredible to witness.\n",
      "\n",
      "The PDD is a wonderful example of how you enhance the connection between communities.\n",
      "\n",
      "What I really love about this project is your desire to make a community, to make interaction among the companies, to find talent.\n",
      "\n",
      "I like very much about the project is that you're working with the air conditions with the winds which are going through the (north-south orientation of the) buildings, that you're building it like this, to use less of the energy.\n",
      "\n",
      "I'm very impressed about all this smart district. First of all, because of the data, because of the understanding of how to use the data to organise the living., Certainly! Here is a transcription of the audio from the provided video:\n",
      "\n",
      "equipped with sensors monitors waste collection and transfers them underground, creating a better working environment for all. For water efficiency, rainwater filtered through rain gardens and eco-ponds, are collected to irrigate green spaces. Through sustainable design, energy optimisation using smart technology and clean energy use, a net zero future is yours to create, here at Punggol Digital District.Certainly, here is a description of the people in the provided video.\n",
      "\n",
      "The video shows two people. The first person is a woman with shoulder-length blonde hair. She is wearing a light pink blazer and a lanyard around her neck. She appears to be in her thirties and has a calm and professional demeanor. She is speaking to the camera, explaining how data is used to organize living and working spaces. She uses her hands to gesture as she speaks.\n",
      "\n",
      "The second person is Lszl Gnczi, from FIABCI Hungary. He is an older man with short, gray hair. He is wearing a dark polo shirt with a logo on it. He appears to be in his sixties or seventies. He has a friendly and approachable demeanor. He is shown speaking to the camera, expressing his positive opinion of a masterplan for a new development. He seems pleased with the design and the inclusion of green spaces. He also comments on the amenities provided for residents., Here is a description of the people in the provided video.\n",
      "\n",
      "The video shows several people. The first person shown is Jake Caine from FIABCI Australia. He is a light-skinned man with short brown hair. He is wearing a black polo shirt and a black baseball cap. He appears to be in his 30s or 40s. He looks serious and focused as he speaks to the camera. His hands are moving as he speaks, indicating he is passionate about what he is saying.\n",
      "\n",
      "Next, there is a group of people looking at a model of a city. There are about ten people in the group. They are a mix of men and women, and they appear to be of various ages and ethnicities. Most of them are wearing casual clothing. They appear to be interested in the model and are looking at it intently. One woman in the group is wearing a mask.\n",
      "\n",
      "Antonio Campagnoli from FIABCI Italy is then shown. He is a middle-aged, light-skinned man with short brown hair and a goatee. He is wearing a light blue and white striped button-down shirt. He looks serious and focused as he speaks to the camera.\n",
      "\n",
      "A group of people wearing bright yellow safety vests and white hard hats are shown standing together. They appear to be on a construction site. There are about ten people in the group. They are a mix of men and women, and they appear to be of various ages and ethnicities. They look attentive as they listen to someone speaking.\n",
      "\n",
      "A woman is shown standing in front of a model of a city. She is wearing a black polo shirt. She is speaking and gesturing with her hands. She appears to be explaining something about the model. A man is standing behind her, with his arms crossed. He appears to be listening to her.\n",
      "\n",
      "Antonio Campagnoli is shown again, speaking to the camera.\n",
      "\n",
      "David Steiner from FIABCI Austria is shown. He is a light-skinned man with short brown hair. He is wearing a light pink button-down shirt. He looks happy and friendly as he speaks to the camera.\n",
      "\n",
      "Another group of people are shown looking at a model of a city. There are about six people in the group. They are a mix of men and women, and they appear to be of various ages and ethnicities. They appear to be interested in the model and are looking at it intently. One woman in the group is wearing a mask.\n",
      "\n",
      "A close-up of some air conditioning system components is shown.\n",
      "\n",
      "Another view of the model of the city is shown.\n",
      "\n",
      "David Steiner is shown again, speaking to the camera.\n",
      "\n",
      "Alissa Bankovska from FIABCI Italy is shown. She is a light-skinned woman with shoulder-length blonde hair. She is wearing a light pink blazer. She looks happy and friendly as she speaks to the camera.\n",
      "\n",
      "Alissa Bankovska is shown again, speaking to the camera., Here is a description of the people and animals that appear in the provided video.\n",
      "\n",
      "From [00:00:02][00:00:06], a person is shown from the knees down walking away from the camera. They appear to be wearing gray sweatpants and white sneakers. They are carrying three reusable shopping bags; one green, one yellow, and one blue. The person seems to be walking at a normal pace and shows no particular emotion.\n",
      "\n",
      "From [00:00:18][00:00:30], there are multiple people shown walking in a park-like setting at night. They are blurry and hard to make out, but they appear to be casually walking and talking with each other.  -- Based on the video description provided, answer the following query as accurately as possible:\n",
      "Summarise the PDD project\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "System_Prompts = \"\"\" You are an expert in screening video descriptions and understanding the context and contents of the video.\n",
    "Only answer based on the description of the video provided here: \n",
    "\"\"\"\n",
    "\n",
    "Question_Prompts = \"\"\" -- Based on the video description provided, answer the following query as accurately as possible:\n",
    "\"\"\"\n",
    "\n",
    "videoDesc = combine_column_to_string(shots_df,'description') + combine_column_to_string(shots_df,'associated_text') + combine_column_to_string(shots_df,'associated_speech') + combine_column_to_string(shots_df,'associated_object')\n",
    "\n",
    "combined_prompt = System_Prompts + ' ' + videoDesc + ' ' + Question_Prompts + query\n",
    "\n",
    "\n",
    "print(\"Your prompt: \\n\" + combined_prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "fdd553d4-4b21-4f5b-a2f5-5b402e760397",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response from AI model: \n",
      "\n",
      "The  Punggol Digital District (PDD) in Singapore is a smart and sustainable  development project.  Key features highlighted include:\n",
      "\n",
      "* **Smart Technology Integration:**  The  district utilizes data to optimize living and working spaces, including energy management (demonstrated by a system that suggests switching off lights and AC, and graphs showing energy savings ), waste management (a pneumatic waste conveyance system), and air quality monitoring.  A digital platform monitors and manages electrical, cooling, and waste systems, allowing for  real-time resource optimization.\n",
      "\n",
      "* **Sustainable Design:**  The project incorporates sustainable practices such as rainwater harvesting for irrigation, and building orientation to utilize natural winds and reduce energy consumption from air conditioning.  The goal is a net-zero  future.\n",
      "\n",
      "* **Community Focus:**  The design emphasizes community building, fostering interaction between companies and attracting talent.  Amenities such as a hawker centre, childcare centres, and a community club are included to support a live-work- learn-play lifestyle.  The masterplan includes significant green spaces.\n",
      "\n",
      "* **Infrastructure:**  The district is well-connected to the rest of Singapore via expressways, an integrated bus interchange, and the future Punggol Coast MRT station.  Its proximity to existing amenities and transportation hubs is also emphasized.\n",
      "\n",
      " The video features testimonials from international representatives of FIABCI (International Real Estate Federation) praising the project's innovative and sustainable approach.\n",
      " \n"
     ]
    }
   ],
   "source": [
    "print(\"Response from AI model: \\n\")\n",
    "print(generate_pro(combined_prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b4e459-f69e-4ff2-ba99-58183a7e5a1b",
   "metadata": {},
   "source": [
    "## Method 2: Agent Builder App"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d4b764-925f-4f45-b9a8-13779be843b3",
   "metadata": {},
   "source": [
    "### Create Datastore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846d14e5-841a-49ea-a8b8-81a1cd542f7d",
   "metadata": {},
   "source": [
    "Give 'Discovery Engine Admin' permission access to the service account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b496bf6-9b28-4f36-b2ec-7174636ab3f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"service account: {SVC_ACC}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a91167-8262-41e6-b99a-cfa1c7405500",
   "metadata": {},
   "outputs": [],
   "source": [
    "gcs_uri = \"gs://ai-sb-test/video-rag/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28dfc8ca-1eec-40f3-a95f-9f7fd481bf32",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_data_store(\n",
    "    project_id: str, location: str, data_store_name: str, data_store_id: str\n",
    "):\n",
    "    # Create a client\n",
    "    client_options = (\n",
    "        ClientOptions(api_endpoint=f\"{location}-discoveryengine.googleapis.com\")\n",
    "        if location != \"global\"\n",
    "        else None\n",
    "    )\n",
    "    client = discoveryengine.DataStoreServiceClient(client_options=client_options)\n",
    "\n",
    "    # Initialize request argument(s)\n",
    "    data_store = discoveryengine.DataStore(\n",
    "        display_name=data_store_name,\n",
    "        industry_vertical=\"GENERIC\",\n",
    "        content_config=\"NO_CONTENT\",\n",
    "    )\n",
    "\n",
    "    request = discoveryengine.CreateDataStoreRequest(\n",
    "        parent=discoveryengine.DataStoreServiceClient.collection_path(\n",
    "            project_id, location, \"default_collection\"\n",
    "        ),\n",
    "        data_store=data_store,\n",
    "        data_store_id=data_store_id,\n",
    "    )\n",
    "    operation = client.create_data_store(request=request)\n",
    "\n",
    "    # Make the request\n",
    "    # The try block is necessary to prevent execution from haulting due to an error being thrown when the datastore takes a while to instantiate\n",
    "    try:\n",
    "        response = operation.result(timeout=90)\n",
    "    except:\n",
    "        print(\"long-running operation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fad3d2-5fdd-4d3a-9e74-f2a406e18260",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The datastore name can only contain lowercase letters, numbers, and hyphens\n",
    "DATASTORE_NAME = f\"{UNIQUE_PREFIX}-datastore\"\n",
    "DATASTORE_ID = f\"{DATASTORE_NAME}-id\"\n",
    "LOCATION = 'global'\n",
    "\n",
    "# print variables for verification\n",
    "print(f\"Datastore name: {DATASTORE_NAME}\")\n",
    "print(f\"Datastore ID: {DATASTORE_ID}\")\n",
    "\n",
    "# Create the datastore\n",
    "try:\n",
    "    create_data_store(PROJECT_ID, LOCATION, DATASTORE_NAME, DATASTORE_ID)\n",
    "    print(f\"Datastore {DATASTORE_ID} successfully created\")\n",
    "except:\n",
    "    print(\"Datastore may already exist\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afff1bc2-9f0b-4f7a-8109-e90610f075f6",
   "metadata": {},
   "source": [
    "### Import csv from bucket to datastore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24f9167-8931-4578-9594-a747eea344ef",
   "metadata": {},
   "source": [
    "This section may take up to 5 - 10 mins to complete the import to the datastore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a02255-d05b-45f3-af07-f6d808d0e3db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Helper Function to import documents from GCS bucket into datastore\n",
    "def import_documents(\n",
    "    project_id: str,\n",
    "    location: str,\n",
    "    data_store_id: str,\n",
    "    gcs_uri: str,\n",
    "):\n",
    "    # Create a client\n",
    "    client_options = (\n",
    "        ClientOptions(api_endpoint=f\"{location}-discoveryengine.googleapis.com\")\n",
    "        if location != \"global\"\n",
    "        else None\n",
    "    )\n",
    "    client = discoveryengine.DocumentServiceClient(client_options=client_options)\n",
    "\n",
    "    # The full resource name of the search engine branch.\n",
    "    # e.g. projects/{project}/locations/{location}/dataStores/{data_store_id}/branches/{branch}\n",
    "    parent = client.branch_path(\n",
    "        project=project_id,\n",
    "        location=location,\n",
    "        data_store=data_store_id,\n",
    "        branch=\"default_branch\",\n",
    "    )\n",
    "\n",
    "    source_documents = [f\"{gcs_uri}/*\"]\n",
    "\n",
    "    request = discoveryengine.ImportDocumentsRequest(\n",
    "        parent=parent,\n",
    "        gcs_source=discoveryengine.GcsSource(\n",
    "            input_uris=source_documents, data_schema=\"csv\"\n",
    "        ),\n",
    "        auto_generate_ids = True,\n",
    "        # Options: `FULL`, `INCREMENTAL`\n",
    "        reconciliation_mode=discoveryengine.ImportDocumentsRequest.ReconciliationMode.INCREMENTAL,\n",
    "    )\n",
    "\n",
    "    # Make the request\n",
    "    operation = client.import_documents(request=request)\n",
    "\n",
    "    response = operation.result()\n",
    "\n",
    "    # Once the operation is complete,\n",
    "    # get information from operation metadata\n",
    "    metadata = discoveryengine.ImportDocumentsMetadata(operation.metadata)\n",
    "\n",
    "    # Handle the response\n",
    "    return operation.operation.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ef0497-4351-45cb-8a5d-c63bd8b8540a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import_documents(PROJECT_ID, LOCATION, DATASTORE_ID, BUCKET_URI)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca73f88-f8f9-4dfb-9e80-f9ce90ae7deb",
   "metadata": {},
   "source": [
    "## Create a Search Engine for your datastore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9968fc04-1b14-452a-a758-dd96c6de3022",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Helper function to create a Vertex Search Engine\n",
    "def create_engine(\n",
    "    project_id: str, location: str, data_store_name: str, data_store_id: str\n",
    "):\n",
    "    # Create a client\n",
    "    client_options = (\n",
    "        ClientOptions(api_endpoint=f\"{location}-discoveryengine.googleapis.com\")\n",
    "        if location != \"global\"\n",
    "        else None\n",
    "    )\n",
    "    client = discoveryengine.EngineServiceClient(client_options=client_options)\n",
    "\n",
    "    # Initialize request argument(s)\n",
    "    config = discoveryengine.Engine.SearchEngineConfig(\n",
    "        search_tier=\"SEARCH_TIER_ENTERPRISE\", search_add_ons=[\"SEARCH_ADD_ON_LLM\"]\n",
    "    )\n",
    "\n",
    "    engine = discoveryengine.Engine(\n",
    "        display_name=data_store_name,\n",
    "        solution_type=\"SOLUTION_TYPE_SEARCH\",\n",
    "        industry_vertical=\"GENERIC\",\n",
    "        data_store_ids=[data_store_id],\n",
    "        search_engine_config=config,\n",
    "    )\n",
    "\n",
    "    request = discoveryengine.CreateEngineRequest(\n",
    "        parent=discoveryengine.DataStoreServiceClient.collection_path(\n",
    "            project_id, location, \"default_collection\"\n",
    "        ),\n",
    "        engine=engine,\n",
    "        engine_id=engine.display_name,\n",
    "    )\n",
    "\n",
    "    # Make the request\n",
    "    operation = client.create_engine(request=request)\n",
    "    response = operation.result(timeout=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d62db14-fb9f-4382-9c4f-83d5e214ed88",
   "metadata": {},
   "source": [
    "Wait for 5 mins, to allow both the datastore and app to load properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aef3fae-7d01-4211-9a91-617410b73ca2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "try:\n",
    "    create_engine(PROJECT_ID, LOCATION, DATASTORE_NAME, DATASTORE_ID)\n",
    "except:\n",
    "    print(\"App may already be created\")\n",
    "time.sleep(300)\n",
    "print(f\"{DATASTORE_NAME} app created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8136f334-3a1d-4877-a802-952d99642fd8",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Updating the config for the App"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a807a85c-868a-49c6-a9c5-7c144dc64ba3",
   "metadata": {
    "tags": []
   },
   "source": [
    "This part will be done manually.\n",
    "1. Go to [Agent Builder](https://console.cloud.google.com/gen-app-builder/engines?hl=en-GB) and select your app\n",
    "2. On the left panel, select 'Data'\n",
    "3. Select the 'Schema'tab\n",
    "4. If any of the fields in the 'Retrievable' column are disabled, click 'Edit' and enable it.\n",
    "5. On the left panel, select 'Congfigurations'\n",
    "6. Select the 'UI' tab\n",
    "7. Under 'Data display options' open 'Configure fields in result'\n",
    "8. Customise answer UI \n",
    "9. Click 'SAVE AND PUBLISH'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42820a22-86a3-44e1-92b3-d6e2c91c2d6a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Previewing App"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a4d68f-77d1-42e0-a177-a63df784df1e",
   "metadata": {},
   "source": [
    "On the left panel, select 'Preview' and try searching for something to test the app"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c286cd01-4c9c-4187-9ee5-2aad75b236b4",
   "metadata": {},
   "source": [
    "## The End"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-env-pytorch-pytorch",
   "name": "workbench-notebooks.m124",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m124"
  },
  "kernelspec": {
   "display_name": "PyTorch 1-13 (Local)",
   "language": "python",
   "name": "conda-env-pytorch-pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
